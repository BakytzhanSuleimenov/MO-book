

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Support Vector Machines for Binary Classification &#8212; Companion Notebooks for Data-Driven Optimization in Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-DVQ7NZ8CYZ"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-DVQ7NZ8CYZ');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/05/svm-linear';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Extra material: Refinery production and shadow pricing" href="refinery-production.html" />
    <link rel="prev" title="Markowitz portfolio optimization" href="markowitz_portfolio.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo-02.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo-02.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Data-Driven Mathematical Optimization in Python
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../01/01.00.html">1. Mathematical Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../01/production-planning.html">A Production Planning Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/production-planning-basic.html">A Basic Pyomo Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/production-planning-advanced.html">A Data-Driven Pyomo Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../02/02.00.html">2. Linear Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../02/bim.html">BIM production</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/lad-regression.html">LAD Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/mad-portfolio-optimization.html">MAD portfolio optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/L1-regression-wine-quality.html">Wine quality prediction with L1 regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/bim-maxmin.html">BIM production for worst case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/bim-fractional.html">BIM production variants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/bim-rawmaterialplanning.html">BIM production using demand forecasts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/multiproductionfaciliity_worstcase.html">Extra material: Multi-product facility production</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../03/03.00.html">3. Mixed Integer Linear Programming</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../03/bim-perturbed.html">BIM production with perturbed data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/shift-scheduling.html">Workforce shift scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/simple-production-model-gdp.html">Production model using disjunctions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/machine-scheduling.html">Machine Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/recharging-electric-vehicle.html">Recharging strategy for an electric vehicle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/bim-production-revisited.html">BIM production revisited</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/cryptarithms.html">Extra material: Cryptarithms puzzle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/strip-packing.html">Extra material: Strip packing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/job-shop-scheduling.html">Extra material: Job shop scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/maintenance-planning.html">Extra material: Maintenance planning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../04/04.00.html">4. Network Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../04/dinner-seat-allocation.html">Dinner seating arrangement</a></li>

<li class="toctree-l2"><a class="reference internal" href="../04/gasoline-distribution.html">Gasoline distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/cryptocurrency-arbitrage.html">Cryptocurrency arbitrage search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/shortest-path-road-networks.html">Extra material: Shortest path in real life</a></li>



<li class="toctree-l2"><a class="reference internal" href="../04/power-network.html">Extra material: Energy dispatch problem</a></li>




</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="05.00.html">5. Convex Optimization</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="milk-pooling.html">Milk pooling and blending</a></li>
<li class="toctree-l2"><a class="reference internal" href="ols-regression.html">Ordinary Least Squares (OLS) Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="markowitz_portfolio.html">Markowitz portfolio optimization</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Support Vector Machines for Binary Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="refinery-production.html">Extra material: Refinery production and shadow pricing</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../06/06.00.html">6. Conic Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../06/economic-order-quantity.html">Economic Order Quantity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06/kelly-criterion.html">The Kelly Criterion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06/markowitz_portfolio_revisited.html">Markowitz portfolio optimization revisited</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06/building-insulation.html">Optimal Design of Multilayered Building Insulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06/investment-wheel.html">Extra material: Luenberger’s Investment Wheel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06/optimal-growth-portfolios.html">Extra material: Optimal Growth Portfolios</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../07/07.00.html">7. Accounting for Uncertainty: Optimization Meets Reality</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../07/fleet-assignment.html">Fleet assignment problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07/bim-robustness-analysis.html">Robustness analysis of BIM production plan via simulations</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../08/08.00.html">8. Robust Optimization - Single Stage Problems</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../08/bim-robust-optimization.html">Robust BIM microchip production problem</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../09/09.00.html">9. Stochastic Optimization - Single Stage Problems</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../09/pop-up_shop.html">Pop-up shop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09/markowitz_portfolio_with_chance_constraint.html">Markowitz portfolio optimization with chance constraints</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09/seafood.html">Stock optimization for seafood distribution center</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../10/10.00.html">10. Two-Stage Problems</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../10/airline-seating.html">Airline seat allocation problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10/farmer.html">The Farmer’s Problem and Variants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10/opf-wind-curtailment.html">Two-stage energy dispatch optimization with wind curtailment</a></li>

<li class="toctree-l2"><a class="reference internal" href="../10/opf-ldr.html">Two-stage energy dispatch optimization using linear decision rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10/ccg.html">Two-stage Production Planning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../pyomo_style_guide.html">Appendix: Pyomo style guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/mobook/MO-book/blob/main/notebooks/05/svm-linear.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/mobook/MO-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/mobook/MO-book/issues/new?title=Issue%20on%20page%20%2Fnotebooks/05/svm-linear.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notebooks/05/svm-linear.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Support Vector Machines for Binary Classification</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-classification">Binary Classification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-set">The Data Set</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#read-data">Read data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#select-features-and-training-sets">Select features and training sets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-machines-svm">Support vector machines (SVM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-linear-svm-classifier">A linear SVM classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-metrics">Performance metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-linear-optimization-model-to-train-a-linear-svm">A linear optimization model to train a linear SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyomo-implementation">Pyomo implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-conic-optimization-model-for-a-linear-svm">A conic optimization model for a linear SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#primal-formulation">Primal formulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dual-formulation">Dual formulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyomo-implementation-of-the-conic-dual">Pyomo implementation of the conic dual</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-kernelized-svm">A kernelized SVM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#full-dataset">Full Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Pyomo Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-svm-dual">The SVM Dual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliographic-notes">Bibliographic Notes</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <span class="target" id="index-0"></span><span class="target" id="index-1"></span><span class="target" id="index-2"></span><span class="target" id="index-3"></span><section class="tex2jax_ignore mathjax_ignore" id="support-vector-machines-for-binary-classification">
<span id="index-4"></span><h1>Support Vector Machines for Binary Classification<a class="headerlink" href="#support-vector-machines-for-binary-classification" title="Permalink to this heading">#</a></h1>
<p>Support Vector Machines (SVM) are supervised machine learning models. This notebook shows how to implement an SVM  for binary classification using linear and conic programming. The first implementation produces linear support vector machines that separates the “feature space” with a hyperplane. This is demonstrated for both primal and dual formulations. The dual formulation extends naturally to binary classification in high order feature spaces.</p>
<p>Like other machine learning techniques based on regression, an SVM classifier can be implemented as the solution to an optimization problem. The optimization problem runs once using training samples with known outcomes to produce parameters for a classifier. The resulting classifier can then be use to classify data with unknown outcomes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># install Pyomo and solvers</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">types</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/mobook/MO-book/main/python/helper.py&quot;</span>
<span class="n">helper</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">ModuleType</span><span class="p">(</span><span class="s2">&quot;helper&quot;</span><span class="p">)</span>
<span class="n">exec</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">helper</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>

<span class="n">helper</span><span class="o">.</span><span class="n">install_pyomo</span><span class="p">()</span>
<span class="n">helper</span><span class="o">.</span><span class="n">install_mosek</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>pyomo was previously installed
mosek was previously installed
</pre></div>
</div>
</div>
</div>
<section id="binary-classification">
<h2>Binary Classification<a class="headerlink" href="#binary-classification" title="Permalink to this heading">#</a></h2>
<p>Binary classifiers are functions designed to answer questions such as “does this medical test indicate disease?”, “will this specific customer enjoy that specific movie?”, “does this photo include a car?”, or “is this banknote genuine or counterfeit?” These questions are answered based on the values of “features”, which may include physical measurements or other types of data collected from a representative sample with known outcomes.</p>
<p>For example, consider a device installed in a vending machine to detect banknotes. The classifier’s goal is to accurately identify and accept genuine banknotes while rejecting counterfeit ones. The classifier’s performance can be assessed using definitions in following table, where “positive” refers to an instance of a genuine banknote.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p></p></th>
<th class="head text-center"><p>Predicted Positive</p></th>
<th class="head text-center"><p>Predicted Negative</p></th>
<th class="head text-left"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Actual Positive</p></td>
<td class="text-center"><p>True Positive (TP)</p></td>
<td class="text-center"><p>False Negative (FN)</p></td>
<td class="text-left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Actual Negative</p></td>
<td class="text-center"><p>False Positive (FP)</p></td>
<td class="text-center"><p>True Negative (TN)</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
<p>A vending machine user would be frustrated if a genuine banknote is incorrectly rejected as a false negative. <strong>Recall</strong> is defined as the number of true positives (TP) divided by the total number of actual positives (TP + FN). A high recall implies a low false negative rate, making it the preferred outcome for users.</p>
<p>The vending machine owner, on the other hand, wants the machine to avoid accepting counterfeit banknotes and would therefore prefer a low number of false positives (FP). <strong>Precision</strong> is the number of true positives (TP) divided by the total number of predicted positives (TP + FP). A high precision implies a low false positive rate, making it the preferred outcome for the owner.</p>
<ul class="simple">
<li><p><strong>Recall</strong>: The number of true positives divided by the total number of actual positives. High recall indicates a low false negative rate.</p></li>
<li><p><strong>Precision</strong>: The number of true positives identified by the model divided by the total number of predicted positives, which includes both true and false positives. High precision indicates a low false positive rate.</p></li>
</ul>
<p>To achieve high recall, a classifier can follow the “innocent until proven guilty” standard, rejecting banknotes only when certain they are counterfeit. To achieve high precision, a classifier can adopt the “guilty unless proven innocent” standard, accepting banknotes only when certain they are genuine. The challenge in developing binary classifiers is to balance these conflicting objectives and optimize performance from both perspectives simultaneously.</p>
</section>
<section id="the-data-set">
<h2>The Data Set<a class="headerlink" href="#the-data-set" title="Permalink to this heading">#</a></h2>
<p>The following data set contains data from a collection of known genuine and known counterfeit banknote specimens. The data includes four continuous statistical measures obtained from the wavelet transform of banknote images named “variance”, “skewness”, “curtosis”, and “entropy”, and a binary variable named “class” which is 0 if genuine and 1 if counterfeit.</p>
<p><a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/banknote+authentication">https://archive.ics.uci.edu/ml/datasets/banknote+authentication</a></p>
<section id="read-data">
<h3>Read data<a class="headerlink" href="#read-data" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># read data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data_banknote_authentication.txt&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;curtosis&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Banknotes&quot;</span>

<span class="c1"># show a few rows</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variance</th>
      <th>skewness</th>
      <th>curtosis</th>
      <th>entropy</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.62160</td>
      <td>8.6661</td>
      <td>-2.8073</td>
      <td>-0.44699</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.54590</td>
      <td>8.1674</td>
      <td>-2.4586</td>
      <td>-1.46210</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.86600</td>
      <td>-2.6383</td>
      <td>1.9242</td>
      <td>0.10645</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.45660</td>
      <td>9.5228</td>
      <td>-4.0112</td>
      <td>-3.59440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.32924</td>
      <td>-4.4552</td>
      <td>4.5718</td>
      <td>-0.98880</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get a statistical description of the data set</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variance</th>
      <th>skewness</th>
      <th>curtosis</th>
      <th>entropy</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.433735</td>
      <td>1.922353</td>
      <td>1.397627</td>
      <td>-1.191657</td>
      <td>0.444606</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.842763</td>
      <td>5.869047</td>
      <td>4.310030</td>
      <td>2.101013</td>
      <td>0.497103</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-7.042100</td>
      <td>-13.773100</td>
      <td>-5.286100</td>
      <td>-8.548200</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-1.773000</td>
      <td>-1.708200</td>
      <td>-1.574975</td>
      <td>-2.413450</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.496180</td>
      <td>2.319650</td>
      <td>0.616630</td>
      <td>-0.586650</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.821475</td>
      <td>6.814625</td>
      <td>3.179250</td>
      <td>0.394810</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>6.824800</td>
      <td>12.951600</td>
      <td>17.927400</td>
      <td>2.449500</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="select-features-and-training-sets">
<h3>Select features and training sets<a class="headerlink" href="#select-features-and-training-sets" title="Permalink to this heading">#</a></h3>
<p>Following customary practices, we divide the data set into a <strong>training set</strong> used to trail the classifier, and a <strong>testing set</strong> that will be used to evaluate the performance of the classifier. In addition, we select two dimensional subset of the features to enable plotting of the results for exposition. Since our definition of a positive outcome corresponds to detecting a genuine banknote, we rescale the “class” feature to have values of 1 for genuine banknotes and -1 for counterfeit banknotes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create training and validation test sets</span>
<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># select training features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">]</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># plot the training set</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;kind&quot;</span><span class="p">:</span> <span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="s2">&quot;ax&quot;</span><span class="p">:</span> <span class="n">ax</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">}</span>

<span class="c1"># catch and ignore warnings from matplotlib scatter plot</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;genuine&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;counterfeit&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Banknote Training Set&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Banknote Training Set&#39;)
</pre></div>
</div>
<img alt="../../_images/1571542bc44a0667f2644b51ad43a2a58df491c0d69d78668d33e44c3ee82eaf.png" src="../../_images/1571542bc44a0667f2644b51ad43a2a58df491c0d69d78668d33e44c3ee82eaf.png" />
</div>
</div>
</section>
</section>
<section id="support-vector-machines-svm">
<h2>Support vector machines (SVM)<a class="headerlink" href="#support-vector-machines-svm" title="Permalink to this heading">#</a></h2>
<section id="a-linear-svm-classifier">
<h3>A linear SVM classifier<a class="headerlink" href="#a-linear-svm-classifier" title="Permalink to this heading">#</a></h3>
<p>A linear support vector machine (SVM) is a binary classification method that employs a linear equation to determine the class assignment. The basic  formula is expressed as:</p>
<div class="math notranslate nohighlight">
\[y^{pred} = \text{sgn}\ ( w^\top x + b)\]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> is a point <span class="math notranslate nohighlight">\(x\in\mathbb{R}^p\)</span> in “feature” space. Here <span class="math notranslate nohighlight">\(w\in \mathbb{R}^p\)</span> represents a set of coefficients, <span class="math notranslate nohighlight">\(w^\top x\)</span> is the dot product, and <span class="math notranslate nohighlight">\(b\)</span> is a scalar coefficient.  The linear function divides the feature space using the hyperplane defined by <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>. Points on one side of the hyperplane are assigned a positive outcome (+1), while points on the other side are assigned a negative outcome (-1).</p>
<p>The following code cell contains a Python implementation of a linear SVM. An instance of <code class="docutils literal notranslate"><span class="pre">LinearSVM</span></code> is defined with a coefficient vector <span class="math notranslate nohighlight">\(w\)</span> and a scalar <span class="math notranslate nohighlight">\(b\)</span>. In this implementation, all data and parameters are provided as Pandas Series or DataFrame objects, and use the Pandas <code class="docutils literal notranslate"><span class="pre">.dot()</span></code> function is used to compute the necessary dot product.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">LinearSvm</span><span class="p">():</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A visual inspection of training set for the banknote, shown above, shows the two dimensional feature set can be roughly split along the vertical axis where “variance” is zero. Most of the positive outcomes are on the right of the axis, most of the negative outcomes on the left. Since <span class="math notranslate nohighlight">\(w\)</span> is a vector normal to this surface, we choose</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
    w &amp; = \begin{bmatrix} w_{variance} \\ w_{skewness} \end{bmatrix} = \begin{bmatrix} 1 \\ 0 \end{bmatrix},
    \qquad b = 0
\end{align}
\end{split}\]</div>
<p>The code cell below evaluates the accuracy of the linear SVM by calculating the <strong>accuracy score</strong>, which is the fraction of samples that were predicted accurately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visual estimaate of w and b for a linear classifier</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s1">&#39;variance&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;skewness&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># create an instance of LinearSVM</span>
<span class="n">svm_v0</span> <span class="o">=</span> <span class="n">LinearSvm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># predictions for the training set</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_v0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># fraction of correct predictions</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">accuracy_score</span><span class="si">:</span><span class="s2"> 0.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy =  87.3%
</pre></div>
</div>
</div>
</div>
</section>
<section id="performance-metrics">
<h3>Performance metrics<a class="headerlink" href="#performance-metrics" title="Permalink to this heading">#</a></h3>
<p>The accuracy score alone is not always a reliable metric for evaluating the performance of binary classifiers. For instance, when one outcome is significantly more frequent than the other, a classifier that always predicts the more common outcome without regard to the feature vector can achieve. Moreover, in many applications, the consequences of a false positive can differ from those of a false negative. For these reasons, we seek a more comprehensive set of metrics to compare binary classifiers. A <a class="reference external" href="https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7">detailed discussion on this topic</a> recommends the <a class="reference external" href="https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a">Matthews correlation coefficient (MCC)</a> as a reliable performance measure for binary classifiers.</p>
<p>The code below demonstrates an example of a function that evaluates the performance of a binary classifier and returns the Matthews correlation coefficient as its output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function calculates and displays the recall, precision, and Matthews correlation coefficient (MCC)</span>
<span class="sd">    for a binary classifier based on its true labels (y_true) and predicted labels (y_pred).</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">    y_true (array-like): A list or array containing the true labels of the samples.</span>
<span class="sd">    y_pred (array-like): A list or array containing the predicted labels of the samples.</span>
<span class="sd">    verbose (bool, optional): If True, the function prints and displays the calculated metrics and </span>
<span class="sd">                              confusion matrix. Defaults to True.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    float: The calculated Matthews correlation coefficient (MCC).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Calculate the elements of the confusion matrix</span>
    <span class="n">true_positives</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">false_negatives</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">false_positives</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">true_negatives</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">+</span> <span class="n">true_negatives</span> <span class="o">+</span> <span class="n">false_positives</span> <span class="o">+</span> <span class="n">false_negatives</span>

    <span class="c1"># Calculate the Matthews correlation coefficient (MCC)</span>
    <span class="n">mcc_numerator</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">*</span> <span class="n">true_negatives</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">false_positives</span> <span class="o">*</span> <span class="n">false_negatives</span><span class="p">)</span>
    <span class="n">mcc_denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">false_positives</span><span class="p">)</span> \
                              <span class="o">*</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">false_negatives</span><span class="p">)</span> \
                              <span class="o">*</span> <span class="p">(</span><span class="n">true_negatives</span> <span class="o">+</span> <span class="n">false_positives</span><span class="p">)</span> \
                              <span class="o">*</span> <span class="p">(</span><span class="n">true_negatives</span> <span class="o">+</span> <span class="n">false_negatives</span><span class="p">))</span>
    <span class="n">mcc</span> <span class="o">=</span> <span class="n">mcc_numerator</span> <span class="o">/</span> <span class="n">mcc_denominator</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Matthews correlation coefficient (MCC) = </span><span class="si">{</span><span class="n">mcc</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># report recall and precision, and accuracy</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">false_positives</span><span class="p">)</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">false_negatives</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">true_negatives</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision = </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">precision</span><span class="si">:</span><span class="s2"> 0.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span> 
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall = </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">recall</span><span class="si">:</span><span class="s2"> 0.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>    
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">accuracy</span><span class="si">:</span><span class="s2"> 0.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

        <span class="c1"># Display the binary confusion matrix</span>
        <span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="p">[[</span><span class="n">true_positives</span><span class="p">,</span> <span class="n">false_negatives</span><span class="p">],</span> <span class="p">[</span><span class="n">false_positives</span><span class="p">,</span> <span class="n">true_negatives</span><span class="p">]],</span> 
            <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Actual Positive&quot;</span><span class="p">,</span> <span class="s2">&quot;Actual Negative&quot;</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Predicted Positive&quot;</span><span class="p">,</span> <span class="s2">&quot;Predicted Negative&quot;</span><span class="p">])</span>
        <span class="n">display</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mcc</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_v0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.665
Precision =  83.6%
Recall =  84.7%
Accuracy =  83.3%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>122</td>
      <td>22</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>24</td>
      <td>107</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="a-linear-optimization-model-to-train-a-linear-svm">
<h2>A linear optimization model to train a linear SVM<a class="headerlink" href="#a-linear-optimization-model-to-train-a-linear-svm" title="Permalink to this heading">#</a></h2>
<p>A training or validation set consists of <span class="math notranslate nohighlight">\(n\)</span> observations <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> where <span class="math notranslate nohighlight">\(y_i = \pm 1\)</span> and <span class="math notranslate nohighlight">\(x_i\in\mathbb{R}^p\)</span> for <span class="math notranslate nohighlight">\(i=1, \dots, n\)</span>. The training task is to find coefficients <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span> and <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span> to achieve high precision and high recall for the validation set. All points <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> for <span class="math notranslate nohighlight">\(i\in 1, \dots, n\)</span> in a training or validation set are successfully classified if the</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
    y_i (w^\top x_i + b) &amp; &gt; 0 &amp; \forall i = 1, 2, \dots, n.
\end{align}
\]</div>
<p>As written, this condition imposes no scale for <span class="math notranslate nohighlight">\(w\)</span> or <span class="math notranslate nohighlight">\(b\)</span> (that is, if the condition is satisfied for any pair <span class="math notranslate nohighlight">\((w, b)\)</span> then it also satisfied for <span class="math notranslate nohighlight">\((\gamma w, \gamma b)\)</span> where <span class="math notranslate nohighlight">\(\gamma &gt; 0\)</span>). It is convenient, therefore, to impose a modified condition for correctly classified points where</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i (w^\top x_i + b) &amp; \geq 1 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\]</div>
<p>which defines a <strong>hard-margin</strong> classifier. The size of the margin is determined by the scale of <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>In practice, it is not always possible to find <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span> that separate all the data perfectly. Therefore, we need to minimize a measure of “things going wrong”. For for this purpose, when fitting an SVM to data it is common to use a <strong>soft-margin</strong> classifier. Given parameters <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>, the <strong>hinge-loss</strong> function is defined as</p>
<div class="math notranslate nohighlight">
\[
\ell(x, y) = \left(1 - y(w^\top x + b)\right)^+,
\]</div>
<p>with the notation <span class="math notranslate nohighlight">\(z^+ = \max(0, z)\)</span>. By design, for a given <span class="math notranslate nohighlight">\((w, b)\)</span>, the hinge-loss function will be zero for any training point correctly classified by the corresponding hard-margin classifier. The hinge-loss function will be less than one for any point correctly classified by <span class="math notranslate nohighlight">\(y_i (w^\top x_i + b) &gt; 0\)</span>. Otherwise the hinge-loss function is greater than one for any misclassified point, and grows in proportion to how far away the feature vector is from the separation plane.</p>
<p>These properties make the hinge-loss function useful for training a linear support vector machine. The training problem is formulated as minimizing the hinge-loss function over all the data samples:</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
    \min_{w, b} \frac{1}{n}\sum_{i=1}^n \left(1 - y_i(w^\top x_i + b)\right)^+ .
\end{align*}
\]</div>
<p>Practice has shown that minimizing this term alone produces classifiers with large entries for <span class="math notranslate nohighlight">\(w\)</span> which performs poorly on new data samples. For that reason, <strong>regularization</strong> adds a term to penalize the magnitude of <span class="math notranslate nohighlight">\(w\)</span>. In most formulations a norm <span class="math notranslate nohighlight">\(\|w\|\)</span> is used for regularization, commonly a sum of squares such as <span class="math notranslate nohighlight">\(\|w\|_2^2\)</span>. Another choice is <span class="math notranslate nohighlight">\(\|w\|_1\)</span> which, similar to Lasso regression, may result in sparse weighting vector <span class="math notranslate nohighlight">\(w\)</span> indicating which elements of the feature vector can be neglected for classification purposes. These considerations result in the objective function</p>
<div class="math notranslate nohighlight">
\[
    \min_{w, b}\left[ \lambda \|w\|_1 + \frac{1}{n}\sum_{i=1}^n \left(1 - y_i(w^\top x_i + b)\right)^+ \right]
\]</div>
<p>By introducing <span class="math notranslate nohighlight">\(n\)</span> auxiliary non-negative variables <span class="math notranslate nohighlight">\(z\)</span>’s, the the needed weights are a solution to following LP:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min\quad  &amp; \lambda \|w\|_1 + \frac{1}{n} \sum_{i=1}^n z_i \\
\text{s.t.} \quad &amp;  z_i \geq 1 - y_i(w^\top x_i + b) &amp; \forall i = 1, \dots, n \\
&amp; z_i\geq 0 &amp; \forall i = 1, \dots, n \\
&amp; w\in\mathbb{R}^p \\
&amp; b\in\mathbb{R} \\
\end{align*}
\end{split}\]</div>
<p>This is the primal optimization problem in decision variables <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span>, <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span>, and <span class="math notranslate nohighlight">\(z\in\mathbb{R}^n\)</span>, a total of <span class="math notranslate nohighlight">\(n + p + 1\)</span> unknowns with <span class="math notranslate nohighlight">\(2n\)</span> constraints. This can be recast as a linear program with the usual technique of setting <span class="math notranslate nohighlight">\(w = w^+ - w^-\)</span> where <span class="math notranslate nohighlight">\(w^+\)</span> and <span class="math notranslate nohighlight">\(w^-\)</span> are non-negative. Then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min\quad  &amp;\lambda \sum_{j=1}^p (w^+_j + w^-_j) + \frac{1}{n}  \sum_{i=1}^n z_i \\
\text{s.t.} \quad &amp;  z_i \geq 1 - y_i((w^+ - w^-)^\top x_i + b) &amp; \forall i = 1, \dots, n \\
&amp; z_i \geq 0 &amp; \forall i = 1, \dots, n \\
&amp; w^+_j, w^-_j \geq 0 &amp; \forall j = 1, \dots, p \\
&amp; b\in\mathbb{R} \\
\end{align*}
\end{split}\]</div>
<section id="pyomo-implementation">
<h3>Pyomo implementation<a class="headerlink" href="#pyomo-implementation" title="Permalink to this heading">#</a></h3>
<p>This optimization model for a linear SVM is implemented as a subclass of Pyomo <code class="docutils literal notranslate"><span class="pre">ConcreteClass</span></code>. An instance of the optimization model is created with a training set</p>
<p>The following Pyomo implementation of an this optimization model for a linear support vector machine is broken into two components. The first component is the SVM itself, which will be Python object parameterized by the coefficients <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span> described above, and with methods to initialize itself, validate itself with test data is available, and produce predictions. This can be small Python class with a small memory footprint for instances of the class.</p>
<p>The second component is a linear SVM <em>Factory</em> that produces instances of SVM objects from training data and other specifications. This is where the Pyomo model will be embedded.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>

<span class="k">def</span> <span class="nf">linearSvmFactory</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        
    <span class="n">m</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">()</span>

    <span class="c1"># use dataframe columns and index to index vars and constraints</span>
    <span class="n">m</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">initialize</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">initialize</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="c1"># decision variables</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wp</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">P</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wn</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">P</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Expression</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">P</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">w</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">wp</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">wn</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">lasso</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">N</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambd</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">wp</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">wn</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">P</span><span class="p">)</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Constraint</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">N</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">hingeloss</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">P</span><span class="p">)</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>

    <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;cbc&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">P</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">P</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">LinearSvm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="n">svm_v1</span> <span class="o">=</span> <span class="n">linearSvmFactory</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm_v1</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm_v1</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>variance    0.242992
skewness    0.053856
dtype: float64
0.016779743
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_v1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.716
Precision =  81.3%
Recall =  93.8%
Accuracy =  85.5%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>135</td>
      <td>9</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>31</td>
      <td>100</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7156161256382129
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">xlim</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">ylim</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">svm_v1</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="o">-</span> <span class="n">svm_v1</span><span class="o">.</span><span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="n">svm_v1</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="s2">&quot;skewness&quot;</span><span class="p">]</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_v1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;kind&quot;</span><span class="p">:</span> <span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="s2">&quot;ax&quot;</span><span class="p">:</span> <span class="n">ax</span><span class="p">,</span> <span class="s2">&quot;xlim&quot;</span><span class="p">:</span> <span class="n">xlim</span><span class="p">,</span> <span class="s2">&quot;ylim&quot;</span><span class="p">:</span> <span class="n">ylim</span><span class="p">}</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True Positives&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;cyan&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;magenta&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;False Positives&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/9cf4821f39c3888b5e63edabe392076f05fd9e4b4b644343684fabddfe6a7781.png" src="../../_images/9cf4821f39c3888b5e63edabe392076f05fd9e4b4b644343684fabddfe6a7781.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">xlim</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">ylim</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;kind&quot;</span><span class="p">:</span> <span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="s2">&quot;xlim&quot;</span><span class="p">:</span> <span class="n">xlim</span><span class="p">,</span> <span class="s2">&quot;ylim&quot;</span><span class="p">:</span> <span class="n">ylim</span><span class="p">}</span>

<span class="c1"># catch and ignore a warning that may be a bug with matplotlib scatter plot</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True Positives&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Sensitivity (or Recall) = TP / (TP + FN)&quot;</span><span class="p">)</span>
    
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;False Positives&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Specificity = TN / (TN + FP)&quot;</span><span class="p">)</span>
    
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True Positives&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;False Positives&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Precision = TP / (TP + FP)&quot;</span><span class="p">)</span>
    
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True Negatives&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;False Negatives&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Negative Predictive Value = TN / (TN + FN)&quot;</span><span class="p">)</span>
    
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/35cab1146f9f06438c982b02c1f128589fd10f0f6ba6b25c9bd15f9ab1b6111f.png" src="../../_images/35cab1146f9f06438c982b02c1f128589fd10f0f6ba6b25c9bd15f9ab1b6111f.png" />
</div>
</div>
</section>
</section>
<section id="a-conic-optimization-model-for-a-linear-svm">
<h2>A conic optimization model for a linear SVM<a class="headerlink" href="#a-conic-optimization-model-for-a-linear-svm" title="Permalink to this heading">#</a></h2>
<section id="primal-formulation">
<h3>Primal formulation<a class="headerlink" href="#primal-formulation" title="Permalink to this heading">#</a></h3>
<p>The standard formulation of a linear support vector machine uses training sets with <span class="math notranslate nohighlight">\(p\)</span>-element feature vectors <span class="math notranslate nohighlight">\(x_i\in\mathbb{R}^p\)</span>, a classification for those vectors, <span class="math notranslate nohighlight">\(y_i = \pm 1\)</span> and a classifier defined by <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span> and <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span></p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y^{pred} &amp; = \text{sgn}(w^\top x + b)
\end{align*}
\]</div>
<p>The purpose of training is to find values for <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>. The parameter <span class="math notranslate nohighlight">\(b\)</span> is an annoying term that unnecessarily clutters the presentation and derivations. As an alternative formulation, consider an augmented feature vector <span class="math notranslate nohighlight">\(\bar{x} = (1, x) \in \mathbb{R}^{p+1}\)</span>, and an augmented parameter vector <span class="math notranslate nohighlight">\(\bar{w} = (b, w) \in \mathbb{R}^{p+1}\)</span>. The linear SVM machine becomes</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y^{pred} &amp; = \text{sgn}(\bar{w}^\top \bar{x})
\end{align*}
\]</div>
<p>If a hard-margin classifier exists for a training or validation set <span class="math notranslate nohighlight">\((\bar{x}_i, y_i)\)</span> for <span class="math notranslate nohighlight">\(i=1, \dots, n\)</span>, then it would satisfy</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i \bar{w}^\top \bar{x}_i &amp; \geq 1 &amp; \forall i \in 1, 2, \dots, n
\end{align*}
\]</div>
<p>The parameter vector <span class="math notranslate nohighlight">\(\bar{w}\)</span> is a vector <span class="math notranslate nohighlight">\(\in \mathbb{R}^{p+1}\)</span>. There is a family of hyperplanes in <span class="math notranslate nohighlight">\(\mathbb{R}^{p+1}\)</span> consisting of all points orthogonal to <span class="math notranslate nohighlight">\(\bar{w}\)</span>. A separatingn A hyperplane. The distance between <span class="math notranslate nohighlight">\(x_i\)</span> and the separating  hyperplane is</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{w}^\top \bar{x}_i}{\|\bar{w}\|}\]</div>
<p>The soft-margin classifier is found by solving</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min \frac{1}{2} \|\bar{w}\|_2^2 &amp; + \frac{c}{n}\sum_{i=1}^n z_i \\
\text{s.t.} \qquad z_i &amp; \geq 1 - y_i \bar{w}^\top \bar{x}_i &amp; \forall i = 1, 2, \dots, n \\
z_i &amp; \geq 0 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\end{split}\]</div>
<p>Recasting as a conic program (EXPLAIN ROTATED Q CONE)</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min\ r + \frac{c}{n} 1^\top z\\
\text{s. t.}\qquad &amp; (r, 1, \bar{w}) \in Q_r^{3 + p} \\
&amp; z + F \bar{w} \geq 1  \\
&amp; z \geq 0 \\
&amp; r\in\mathbb{R} \\
\end{align*}
\end{split}\]</div>
<p><a class="reference external" href="https://pyomo.readthedocs.io/en/stable/library_reference/kernel/index.html">The Kernel Library</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.kernel</span> <span class="k">as</span> <span class="nn">pmo</span>

<span class="k">def</span> <span class="nf">conicSvm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    
    <span class="c1"># data</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="c1"># create model block</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>

    <span class="c1"># decision variables</span>
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="c1"># objective</span>
    <span class="n">m</span><span class="o">.</span><span class="n">primal</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">+</span> <span class="p">(</span><span class="n">c</span><span class="o">/</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">))</span>
    
    <span class="c1"># constraints</span>
    <span class="n">m</span><span class="o">.</span><span class="n">qr</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">)),</span> <span class="n">lb</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>

    <span class="c1"># solve</span>
    <span class="n">pmo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;mosek_direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    
    <span class="c1"># return svm</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]()</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]()</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)})</span>
    
    <span class="k">return</span> <span class="n">LinearSvm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="n">svm_v2</span> <span class="o">=</span> <span class="n">conicSvm</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm_v2</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm_v2</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>variance    0.366216
skewness    0.117057
dtype: float64
-0.036761275865633845
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_v2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.690
Precision =  81.4%
Recall =  91.0%
Accuracy =  84.4%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>131</td>
      <td>13</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>30</td>
      <td>101</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6901072475433397
</pre></div>
</div>
</div>
</div>
</section>
<section id="dual-formulation">
<h3>Dual formulation<a class="headerlink" href="#dual-formulation" title="Permalink to this heading">#</a></h3>
<p>The dual formulation for the SVM provides important insight into how an SVM works, and is the foundation for extending the SVM to nonlinear classification applications using kernels. The dual formulation begins by creating a differentiable Lagrangian with dual factors <span class="math notranslate nohighlight">\(\alpha_i \geq 0\)</span> and <span class="math notranslate nohighlight">\(\beta_i \geq 0\)</span> for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>, the task is to find saddle points of</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L} &amp; = \frac{1}{2} \|\bar{w}\|_2^2 + \frac{c}{n}\sum_{i=1}^n z_i + \sum_{i=1}^n \alpha_i (1 - y_i \bar{w}^\top \bar{x}_i - z_i) + \sum_{i=1}^n \beta_i (-z_i) \\
\end{align*}
\end{split}\]</div>
<p>Taking derivatives with respect to the primal variables</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial \mathcal{L}}{\partial z_i} &amp; = \frac{c}{n} - \alpha_i - \beta_i = 0 \implies 0 \leq \alpha_i \leq \frac{c}{n}\\
\frac{\partial \mathcal{L}}{\partial \bar{w}} &amp; = \bar{w}  - \sum_{i=1}^n \alpha_i y_i \bar{x}_i = 0 \implies  \bar{w} = \sum_{i=1}^n \alpha_i y_i \bar{x}_i \\
\end{align*}
\end{split}\]</div>
<p>results in the dual formulation for the decision variables <span class="math notranslate nohighlight">\(\alpha_i\)</span> for <span class="math notranslate nohighlight">\(i=1, 2, \ldots, n\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\max_{\alpha_i}\ &amp;  \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( \bar{x}_i^\top \bar{x}_j ) \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>This can be arranged in the form of a standard quadratic program in <span class="math notranslate nohighlight">\(n\)</span> variables <span class="math notranslate nohighlight">\(\alpha_i\)</span> for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{\alpha_i}\ &amp; \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( \bar{x}_i^\top \bar{x}_j ) -  \sum_{i=1}^n \alpha_i \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>The symmetric <span class="math notranslate nohighlight">\(n \times n\)</span> <strong>Gram matrix</strong> is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}G = \begin{bmatrix} 
y_1 y_1 \bar{x}_1^\top \bar{x}_1 &amp; \dots &amp; y_1 y_n \bar{x}_1^\top \bar{x}_n \\ 
\vdots &amp; \ddots &amp; \vdots \\ 
y_n y_1 \bar{x}_n^\top \bar{x}_1 &amp; \dots &amp; y_n y_n \bar{x}_n^\top \bar{x}_n 
\end{bmatrix}\end{split}\]</div>
<p>where each entry is dot product of two vectors <span class="math notranslate nohighlight">\(\bar{x}_i, \bar{x}_j \in \mathbb{R}^{p+1}\)</span>.</p>
<p>Compared to the primal, the dual formulation appears to have reduced the number of decision variables from <span class="math notranslate nohighlight">\(n + p + 1\)</span> to <span class="math notranslate nohighlight">\(n\)</span>. But this has come with the penalty of introducing a dense matrix with <span class="math notranslate nohighlight">\(n^2\)</span> coefficients and potential processing time of order <span class="math notranslate nohighlight">\(n^3\)</span>. For large training sets <span class="math notranslate nohighlight">\(n\sim 10^4-10^5\)</span> this becomes a prohibitively expensive calculation. In addition, the Gram matrix is almost sure to be rank deficient for cases <span class="math notranslate nohighlight">\(p \ll n\)</span>. Reformulating the dual problem as a conic program eliminates the need to compute and store the full Gram matrix <span class="math notranslate nohighlight">\(G\)</span>.</p>
<p>The reformulation begins by introducing the <span class="math notranslate nohighlight">\(n \times (p+1)\)</span> matrix <span class="math notranslate nohighlight">\(F\)</span> defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}F = \begin{bmatrix} y_1 \bar{x}_1^\top \\ y_2 \bar{x}_2^\top \\ \vdots \\ y_n \bar{x}_n^\top \end{bmatrix}\end{split}\]</div>
<p>Then introducing an additional decision variable <span class="math notranslate nohighlight">\(r \geq 0\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r - 1^\top \alpha\\
\text{s. t.}\qquad &amp; \alpha^\top F F^\top \alpha \leq 2 r \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>Using the notation <span class="math notranslate nohighlight">\(\mathcal{Q}^m_r\)</span> for a <a class="reference external" href="https://docs.mosek.com/modeling-cookbook/cqo.html#equation-eq-sec-qo-modeling-qset2">rotated quadratic cone</a></p>
<div class="math notranslate nohighlight">
\[\mathcal{Q}^m_r = \{z\in\mathbb{R}^m | 2z_1z_2 \geq z_3^2 + \cdots + z_m^2,\ z_1, z_2 \geq 0 \}\]</div>
<p>The quadratic constraint is reformulated as a rotated quadratic cone</p>
<div class="math notranslate nohighlight">
\[\alpha^\top F F^\top \alpha \leq 2 r \iff (r, 1, F^\top \alpha) \in Q_r^{3 + p}\]</div>
<p>To satisfy the requirements for specifying rotated quadratic cones in Pyomo, let <span class="math notranslate nohighlight">\(z = F^\top\alpha\)</span>. Then</p>
<div class="math notranslate nohighlight">
\[\alpha^\top F F^\top \alpha \leq 2 r \iff z^\top z \leq 2 r \iff (r, 1, z) \in Q_r^{3 + p}\]</div>
<p>The result is a conic program for the dual coefficients <span class="math notranslate nohighlight">\(\alpha\)</span> and auxiliary variables <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(z\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min\ r - 1^\top \alpha\\
\text{s. t.}\qquad &amp; (r, 1, z) \in Q_r^{3 + p} \\
&amp; z = F^\top \alpha \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
&amp; r\in\mathbb{R} \\
\end{align*}
\end{split}\]</div>
<p>The solution to dual formulation also provides an alternative expression for the resulting support vector machine. Let <span class="math notranslate nohighlight">\({SV}\)</span> represent the set of <strong>support vectors</strong>, which can be implemented as the set of indices for which <span class="math notranslate nohighlight">\(\alpha_i &gt; 0\)</span>.
Then SVM can be expressed as either</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
y^{pred} &amp; = \text{sgn}\left( \bar{w}^\top \bar{x} \right)\quad
\text{where}\quad \bar{w} = \sum_{i\in\cal{SV}} \alpha_i y_i \bar{x}_i 
\end{align}
\]</div>
<p>or, more directly, as</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
y^{pred} &amp; =  \text{sgn}\left( \sum_{i\in\cal{SV}} \alpha_i y_i \bar{x}_i^\top \bar{x} \right)
\end{align}
\]</div>
<p>The first formulation produces a more efficient implementation of a linear SVM which is demonstrated in the following Pyomo implementation. The second formulation, however, provides considerable insight into how an SVM works, and is the basis for important generalizations of SVM including the kernelized SVM.</p>
</section>
<section id="pyomo-implementation-of-the-conic-dual">
<h3>Pyomo implementation of the conic dual<a class="headerlink" href="#pyomo-implementation-of-the-conic-dual" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.kernel</span> <span class="k">as</span> <span class="nn">pmo</span>

<span class="k">def</span> <span class="nf">svm_conic_dual</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>
    
    <span class="c1"># decision variables</span>
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">c</span><span class="o">/</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="c1"># objective</span>
    <span class="n">m</span><span class="o">.</span><span class="n">o</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">))</span>

    <span class="c1"># constraints</span>
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">rhs</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span> 
    <span class="n">m</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
    
    <span class="c1"># solve</span>
    <span class="n">pmo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;mosek_direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    
    <span class="c1"># get the support</span>
    <span class="n">S</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span>
    
    <span class="c1"># create and return linear SVM</span>
    <span class="n">w_bar</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">*</span> <span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">S</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">w_bar</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)})</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">w_bar</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
        <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">S</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">X</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">LinearSvm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="n">svm_v3</span> <span class="o">=</span> <span class="n">svm_conic_dual</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm_v3</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="n">svm_v3</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>variance    0.682252
skewness    0.202493
dtype: float64 -0.408522897090956
</pre></div>
</div>
<img alt="../../_images/400bc5682a1e04d322e8bba605f216ef39b1a1321d453b06dd37729d50b667a6.png" src="../../_images/400bc5682a1e04d322e8bba605f216ef39b1a1321d453b06dd37729d50b667a6.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_v3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.723
Precision =  85.8%
Recall =  88.2%
Accuracy =  86.2%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>127</td>
      <td>17</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>21</td>
      <td>110</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7229432921543978
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="a-kernelized-svm">
<h2>A kernelized SVM<a class="headerlink" href="#a-kernelized-svm" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_method">Wikipedia</a></p>
<p>A kernalized version of the support vector machine is given by</p>
<div class="math notranslate nohighlight">
\[y^{pred} = \text{sgn}\left(\sum_{i=1}^n \alpha_i y_i K(x_i, x)\right)\]</div>
<p>where <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> are members of the training set, and <span class="math notranslate nohighlight">\(K(x_i, x)\)</span> is a <strong>kernel function</strong>. Comparing to the dual formulation of a linear SVM, we see that <span class="math notranslate nohighlight">\(K(x_i, x) = x_i^\top x\)</span> which shows an inner product is the kernel function for linear SVM.</p>
<p>Kernel methods extend the framework provided introduced with linear support vector machines to a wider</p>
<p>Recall the dual formulation in standard quadratic program with <span class="math notranslate nohighlight">\(n\)</span> variables <span class="math notranslate nohighlight">\(\alpha_i\)</span> for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{\alpha_i}\ &amp; \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( \bar{x}_i^\top \bar{x}_j ) -  \sum_{i=1}^n \alpha_i \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>where the <span class="math notranslate nohighlight">\(n \times n\)</span> <strong>Gram matrix</strong> is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
G = \begin{bmatrix} 
    y_1 y_1\bar{x}_1^\top \bar{x}_1 &amp; \dots &amp; y_1 y_n\bar{x}_1^\top \bar{x}_n \\ 
    \vdots &amp; \ddots &amp; \vdots \\ 
    y_n y_1 \bar{x}_n^\top \bar{x}_1 &amp; \dots &amp; y_n y_n\bar{x}_n^\top \bar{x}_n 
\end{bmatrix}
\end{split}\]</div>
<p>The “Kernel Trick” entails replacing the inner products <span class="math notranslate nohighlight">\(\bar{x}_i^\top \bar{x}_j\)</span> with the value of a kernel function <span class="math notranslate nohighlight">\(K(\bar{x}_i, \bar{x}_j)\)</span> which results in the optimization problem</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{\alpha_i}\ &amp; \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(\bar{x}_i, \bar{x}_j)  -  \sum_{i=1}^n \alpha_i \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>where the Gram matrix becomes</p>
<div class="math notranslate nohighlight">
\[\begin{split}
G = \begin{bmatrix} 
    y_1 y_1 K(\bar{x}_1, \bar{x}_1) &amp; \dots &amp; y_1 y_n K(\bar{x}_1, \bar{x}_n) \\ 
    \vdots &amp; \ddots &amp; \vdots \\ 
    y_n y_1 K(\bar{x}_n, \bar{x}_1) &amp; \dots &amp; y_n y_n K(\bar{x}_n, \bar{x}_n )
\end{bmatrix}
\end{split}\]</div>
<p>Like an inner product, the kernel functions are measures of similarity between two vector quantities. The twist is that the similarity is measured in a “lifted” or “feature” space. That is, there is a function <span class="math notranslate nohighlight">\(\phi\)</span> that maps <span class="math notranslate nohighlight">\(\bar{x}\)</span></p>
<div class="math notranslate nohighlight">
\[\phi: \mathbb{R}^{p+1} \rightarrow \cal{H}\]</div>
<p>The kernel function</p>
<div class="math notranslate nohighlight">
\[K(\bar{x}, \bar{z}) = \langle \phi(\bar{x}), \phi(\bar{z})\rangle_\cal{H}\]</div>
<p>The resulting predictor is</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
    y^{pred} &amp; = \text{sgn}(\bar{w}^\top \bar{x})
\end{align*}
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\bar{w} = \sum_{i=1}^n \alpha_i y_i \bar{x}_i\]</div>
<div class="math notranslate nohighlight">
\[
\begin{align*}
    y^{pred} &amp; = \text{sgn}\left(\sum_{i=1}^n \alpha_i y_i \bar{x}_i^\top \bar{x}\right)
\end{align*}
\]</div>
<div class="math notranslate nohighlight">
\[
\begin{align*}
    y^{pred} &amp; = \text{sgn}\left(\sum_{i=1}^n \alpha_i y_i K(\bar{x}_i, \bar{x})\right)
\end{align*}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">pyomo.kernel</span> <span class="k">as</span> <span class="nn">pmo</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">x</span> <span class="o">@</span> <span class="n">z</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span> <span class="nf">svm_conic_dual</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
    
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    
    <span class="c1"># convert to numpy arrays for speed</span>
    <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()])</span>
    <span class="n">y_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    
    <span class="c1"># kernel matrix</span>
    <span class="n">G</span> <span class="o">=</span> <span class="p">[[</span><span class="n">y_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">y_</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X_</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:])</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
    
    <span class="c1"># spectral factors for a positive semi-definite matrix</span>
    <span class="n">eigvals</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">eigvals</span> <span class="o">&gt;=</span> <span class="n">tol</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">eigvals</span><span class="p">))</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
    <span class="n">eigvals</span> <span class="o">=</span> <span class="n">eigvals</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    
    <span class="n">F</span> <span class="o">=</span> <span class="n">V</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">eigvals</span><span class="p">))</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>
    
    <span class="c1"># decision variables</span>
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">c</span><span class="o">/</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="c1"># objective</span>
    <span class="n">m</span><span class="o">.</span><span class="n">o</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">))</span>

    <span class="c1"># constraints</span>
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">rhs</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span> 
    <span class="n">m</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
    
    <span class="c1"># solve</span>
    <span class="n">pmo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;mosek_direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    
    <span class="c1"># get svm parameters</span>
    <span class="n">support</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>
    <span class="n">w_aug</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">*</span> <span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">support</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">w_aug</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">w_aug</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">w_aug</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)})</span>

    <span class="k">return</span> <span class="n">LinearSvm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="n">c</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">svm_conic_dual</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="n">svm</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 42, 45, 46, 49, 50, 51, 53, 54, 56, 60, 62, 63, 65, 66, 67, 70, 71, 73, 74, 76, 77, 79, 80, 81, 83, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 106, 107, 109, 111, 114, 115, 116, 117, 118, 119, 121, 122, 125, 126, 127, 128, 129, 130, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 155, 158, 159, 160, 161, 166, 167, 168, 172, 173, 176, 177, 178, 180, 181, 182, 183, 185, 186, 187, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 265, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 285, 286, 288, 292, 293, 294, 298, 299, 303, 304, 305, 306, 307, 310, 311, 312, 313, 315, 319, 320, 322, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 339, 340, 341, 342, 343, 345, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 360, 361, 362, 363, 365, 366, 368, 370, 371, 373, 374, 375, 377, 378, 379, 380, 381, 382, 386, 387, 388, 389, 390, 392, 393, 394, 397, 398, 400, 402, 403, 404, 405, 408, 409, 411, 412, 413, 415, 418, 419, 421, 422, 423, 424, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 445, 446, 448, 450, 452, 453, 455, 456, 457, 458, 459, 460, 461, 463, 464, 466, 467, 469, 472, 473, 474, 475, 479, 480, 481, 482, 485, 486, 487, 488, 489, 490, 492, 493, 495, 496, 499, 500, 501, 502, 505, 508, 509, 511, 514, 516, 517, 521, 522, 523, 524, 528, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 543, 544, 547, 548, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 563, 564, 565, 566, 567, 568, 570, 573, 575, 576, 580, 581, 582, 584, 585, 586, 587, 588, 589, 593, 596, 597, 598, 599, 602, 603, 604, 605, 607, 610, 611, 612, 613, 614, 615, 616, 617, 619, 621, 622, 625, 626, 627, 628, 630, 631, 632, 633, 636, 637, 639, 640, 641, 642, 644, 645, 646, 648, 649, 650, 651, 653, 654, 655, 656, 657, 658, 660, 664, 666, 667, 668, 670, 672, 673, 674, 675, 676, 677, 679, 680, 681, 682, 683, 685, 686, 688, 689, 690, 692, 693, 694, 699, 701, 703, 704, 707, 708, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 724, 727, 728, 729, 730, 731, 732, 733, 734, 736, 737, 738, 739, 740, 741, 744, 745, 746, 747, 748, 749, 750, 751, 753, 754, 755, 756, 757, 758, 760, 761, 762, 763, 764, 765, 766, 767, 769, 771, 772, 774, 776, 777, 779, 782, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 810, 811, 812, 813, 815, 816, 817, 820, 821, 823, 824, 825, 828, 829, 830, 831, 832, 833, 835, 837, 838, 840, 841, 843, 845, 846, 847, 848, 849, 851, 853, 855, 856, 857, 859, 860, 861, 863, 864, 865, 866, 867, 868, 869, 870, 876, 877, 878, 879, 880, 881, 882, 883, 885, 887, 890, 891, 892, 894, 895, 898, 899, 901, 902, 904, 905, 906, 909, 910, 911, 913, 914, 915, 916, 917, 919, 920, 922, 925, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 945, 946, 947, 948, 949, 950, 951, 952, 953, 955, 956, 957, 958, 960, 963, 964, 967, 969, 970, 972, 977, 978, 979, 980, 981, 983, 984, 985, 987, 988, 989, 990, 991, 992, 994, 996, 997, 998, 999, 1002, 1003, 1004, 1005, 1009, 1010, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1021, 1022, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044, 1048, 1049, 1051, 1052, 1053, 1054, 1056, 1057, 1059, 1061, 1062, 1063, 1064, 1065, 1066, 1069, 1070, 1071, 1072, 1073, 1076, 1077, 1078, 1081, 1083, 1084, 1086, 1088, 1090, 1091, 1092, 1094, 1095, 1096]
[-0.08980489  0.36740983  0.05163089  5.2663787   2.31542121 11.25507333]
variance    0.367410
skewness    0.051631
dtype: float64 -0.08980488968121626
</pre></div>
</div>
<img alt="../../_images/5b1f97b05007a8b80f6b692d8f3ff2602ae76cc36ee1b75dc4f9903facdceeec.png" src="../../_images/5b1f97b05007a8b80f6b692d8f3ff2602ae76cc36ee1b75dc4f9903facdceeec.png" />
</div>
</div>
</section>
<section id="full-dataset">
<h2>Full Dataset<a class="headerlink" href="#full-dataset" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create training and validation test sets</span>
<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># select training features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">]</span> <span class="c1">#, &quot;curtosis&quot;, &quot;entropy&quot;]</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="n">c</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">svm_conic_dual</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="n">svm</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>

<span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;variance&#39;, &#39;skewness&#39;, &#39;curtosis&#39;, &#39;entropy&#39;, &#39;class&#39;], dtype=&#39;object&#39;)
variance    0.363410
skewness    0.116214
dtype: float64 -0.04839297368364593
Recall =  0.928
Precision =  0.855
Matthews correlation coefficient (MCC) =  0.743
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>141</td>
      <td>11</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>24</td>
      <td>99</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7434459025462694
</pre></div>
</div>
</div>
</div>
</section>
<section id="id1">
<h2>Pyomo Implementation<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>


<span class="k">def</span> <span class="nf">svm_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">()</span>

    <span class="c1"># zero-based indexing</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">m</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wpos</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wneg</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Constraint</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">hinge_loss</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span> <span class="o">+</span> <span class="n">lambd</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">m</span><span class="o">.</span><span class="n">wpos</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">wneg</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span>
        <span class="p">)</span>

    <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;glpk&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">()</span>

    <span class="c1"># return a binary classifier</span>
    <span class="k">def</span> <span class="nf">svm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">w</span> <span class="o">@</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

    <span class="n">svm</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">w</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>

    <span class="k">return</span> <span class="n">svm</span>


<span class="c1"># create a linear SVM binary classifier</span>

<span class="o">%</span><span class="k">timeit</span> svm = svm_fit(X_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>395 ms ± 23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">svm</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>

    <span class="n">true_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">false_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">false_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">true_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">tp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">true_pos</span><span class="p">)</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">false_pos</span><span class="p">)</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">false_neg</span><span class="p">)</span>
    <span class="n">tn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">true_neg</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;                   Test Data (n = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;                  y = 1       y = -1&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Predict y =  1    </span><span class="si">{</span><span class="n">tp</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">      </span><span class="si">{</span><span class="n">fp</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">    precision = </span><span class="si">{</span><span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Predict y = -1    </span><span class="si">{</span><span class="n">fn</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">      </span><span class="si">{</span><span class="n">tn</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2"> &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;      Recall =     </span><span class="si">{</span><span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">plot</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">w</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">b</span>
        <span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()</span>
        <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="p">[</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">xmin</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">xmax</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">5.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">true_pos</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">true_pos</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">true_neg</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">true_neg</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;true positive&quot;</span><span class="p">,</span> <span class="s2">&quot;true negative&quot;</span><span class="p">])</span>

    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">false_pos</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">false_pos</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">false_neg</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">false_neg</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;false negative&quot;</span><span class="p">,</span> <span class="s2">&quot;false_positive&quot;</span><span class="p">])</span>


<span class="n">svm</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                   Test Data (n = 275)
                  y = 1       y = -1
 Predict y =  1      96        21    precision = 0.821
 Predict y = -1      13       145 
      Recall =     0.881
</pre></div>
</div>
<img alt="../../_images/ecd7a2d53ca06e8d12bb4c4b06ac3160a6801ba965636c71da076765623a0755.png" src="../../_images/ecd7a2d53ca06e8d12bb4c4b06ac3160a6801ba965636c71da076765623a0755.png" />
<img alt="../../_images/e6cfa7742dfe4e26be1f9c87517437e36a20ed258f5e214354aa1b8efdbc3f52.png" src="../../_images/e6cfa7742dfe4e26be1f9c87517437e36a20ed258f5e214354aa1b8efdbc3f52.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_train_full</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_train_full</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_test_full</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_test_full</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># fit svm and test</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">)</span>
<span class="n">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_test_full</span><span class="p">,</span> <span class="n">y_test_full</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                   Test Data (n = 275)
                  y = 1       y = -1
 Predict y =  1     109         0    precision = 1.000
 Predict y = -1       0       166 
      Recall =     1.000
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-svm-dual">
<h2>The SVM Dual<a class="headerlink" href="#the-svm-dual" title="Permalink to this heading">#</a></h2>
<p>Creating the dual of the support vector machine will turn out to have practical consequences. Creating the dual requires a differentiable objective function. For this reason, the regularization term is changed to the 2-norm of <span class="math notranslate nohighlight">\(w\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{z, w, b}\  \frac{1}{2} \|w\|_2^2 + \frac{c}{n}  \sum_{i=1}^n z_i \\
\\
\text{s.t.}\qquad 1 - y_i(w^\top x_i + b) - z_i &amp; \leq 0 &amp; \forall i = 1, \dots, n \\
- z_i &amp; \leq 0 &amp; \forall i = 1, \dots, n
\end{align*}
\end{split}\]</div>
<p>where the regularization parameter shifted to <span class="math notranslate nohighlight">\(c\)</span>, and the constraints restated in standard form. This is a quadratic problem in <span class="math notranslate nohighlight">\(n + p + 1\)</span> variables and <span class="math notranslate nohighlight">\(2n\)</span> constraints.</p>
<p>The Lagrangian <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L} &amp; = \frac{1}{2} \|w\|_2^2 + \frac{c}{n}\sum_{i=1}^n z_i + \sum_{i=1}^n \alpha_i (1 - y_i(w^\top x_i + b) - z_i) + \sum_{i=1}^n \beta_i (-z_i) \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(2n\)</span> non-negative Lagrange multipliers <span class="math notranslate nohighlight">\(\alpha_i \geq 0\)</span> and <span class="math notranslate nohighlight">\(\beta_1 \geq 0\)</span> have been introduced for <span class="math notranslate nohighlight">\(i \in 1,\dots,n\)</span>. Intuitively, the Lagrange variables are penalty weights assigned to the inequality constraints introduced into a modified objective function. If the penalties are large enough then the constraints will be satisfied.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial \mathcal{L}}{\partial z_i} &amp; = \frac{c}{n} - \alpha_i - \beta_i = 0 \implies 0 \leq \alpha_i \leq \frac{c}{n}\\
\frac{\partial \mathcal{L}}{\partial w} &amp; = w  - \sum_{i=1}^n \alpha_i y_i x_i = 0 \implies  w = \sum_{i=1}^n \alpha_i y_i x_i \\
\frac{\partial \mathcal{L}}{\partial b} &amp; = -\sum_{i=1}^n \alpha_i y_i = 0 \implies \sum_{i=1}^n \alpha_i y_i = 0 \\
\end{align*}
\end{split}\]</div>
<p>The dual problem is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\max_{\alpha_i}\ &amp;  \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( x_i^\top x_j ) \\
\text{s. t.}\quad &amp; \sum_{i=1}^n \alpha_i y_i = 0 \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>Like the primal, the dual is a quadratic program. The dual, however, has only <span class="math notranslate nohighlight">\(n\)</span> decision variables compared to <span class="math notranslate nohighlight">\(n + p + 1\)</span> decision variables for the primal, and <span class="math notranslate nohighlight">\(n + 1\)</span> constraints compared to <span class="math notranslate nohighlight">\(2n\)</span> constraints for the primal. This reduction is significant for problems with many features (i.e, large <span class="math notranslate nohighlight">\(p\)</span>), or for large training sets (i.e., large <span class="math notranslate nohighlight">\(n\)</span>). The case of large <span class="math notranslate nohighlight">\(p\)</span> becomes important when extending SVM to nonlinear classification using kernels.</p>
<p>Note, however, that the reduced number of decision variables and constraints in the dual problem requires computing <span class="math notranslate nohighlight">\(\frac{n(n+1)}{2}\)</span> inner products <span class="math notranslate nohighlight">\((x_i^\top x_j)\)</span> for <span class="math notranslate nohighlight">\(i \leq j\)</span> and <span class="math notranslate nohighlight">\(i,j\in \mathbb{R}^n\)</span>.   The inner products can be arranged as a symmetric matrix
$<span class="math notranslate nohighlight">\(
\begin{align*}
K = [k_{i,j}] = X X^\top = \begin{bmatrix}
x_1^\top x_1 &amp; x_1^\top x_2 &amp; \dots &amp; x_1^\top x_n \\
x_2^\top x_1 &amp; x_2^\top x_2 &amp; \dots &amp; x_2^\top x_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_n^\top x_1 &amp; x_n^\top x_2 &amp; \dots &amp;  x_n^\top x_n \\
\end{bmatrix}
\end{align*}
\)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n\times p}\)</span> is the matrix formed by the <span class="math notranslate nohighlight">\(n\)</span> feature vectors <span class="math notranslate nohighlight">\(x_i\)</span> for <span class="math notranslate nohighlight">\(i=1, 2, \dots, n\)</span>. The symmetry of <span class="math notranslate nohighlight">\(K\)</span>, which is known as the Gram matrix (or Grammian) is a consequence of the symmetry of the inner product for real number spaces.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
w^* &amp; = \sum_{i=1}^n \alpha_i^* y_i x_i \\
b^* &amp; = y_k - (w^*)^\top x_k &amp; \text{for any }k\ni 0 &lt; \alpha_k &lt; \frac{c}{n} \\
\end{align*}
\end{split}\]</div>
<p>which can be written entirely in terms of the inner product.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
w^* &amp; = \sum_{i=1}^n \alpha_i^* y_i x_i \\
b^* &amp; = y_k - \sum_{i=1}^n \alpha_i^* y_i x_i^\top x_k &amp; \text{for any }k\ni 0 &lt; \alpha_k &lt; \frac{c}{n} 
\end{align*}
\end{split}\]</div>
<p>Given a value for the feature vector <span class="math notranslate nohighlight">\(x\in\mathbb{R}^p\)</span>, the classifier <span class="math notranslate nohighlight">\(\hat{y} = \text{sgn}\ \left((w^*)^\top x + b^* \right)\)</span> is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\hat{y} &amp; = \text{sgn}\ \left( y_k + \sum_{i=1}^n \alpha_i^* y_i x^\top_i (x - x_k) \right)\\
\end{align*}
\end{split}\]</div>
<p>This is result has important consequences. The key point is that is that the dual optimization problem can be solved with knowledge of the inner products appearing in the Gram matrix <span class="math notranslate nohighlight">\(K\)</span>, and the resulting classifier needs only inner products of training set data with the difference <span class="math notranslate nohighlight">\(x - x_k\)</span> for some <span class="math notranslate nohighlight">\(k\)</span> found in the optimization calculation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>


<span class="k">def</span> <span class="nf">svm_dual_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">()</span>

    <span class="n">X_np</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

    <span class="n">K</span> <span class="o">=</span> <span class="n">X_np</span> <span class="o">@</span> <span class="n">X_np</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># zero-based indexing</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Constraint</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">sumya</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">maximize</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span>
        <span class="p">)</span>

    <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">svm</span><span class="p">():</span>
        <span class="k">pass</span>

    <span class="k">return</span> <span class="n">svm</span>


<span class="c1"># create a linear SVM binary classifier</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

<span class="nn">File ~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pyomo/solvers/plugins/solvers/direct_solver.py:120,</span> in <span class="ni">DirectSolver.solve</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span> 
<span class="g g-Whitespace">    </span><span class="mi">117</span>     <span class="c1"># we&#39;re good to go.</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span>     <span class="n">initial_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">120</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_presolve</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">122</span>     <span class="n">presolve_completion_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">123</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_timing</span><span class="p">:</span>

<span class="nn">File ~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pyomo/solvers/plugins/solvers/direct_solver.py:63,</span> in <span class="ni">DirectSolver._presolve</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span>     <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;The </span><span class="si">{0}</span><span class="s2"> plugin method &#39;_presolve&#39; must be supplied a single problem instance - </span><span class="si">{1}</span><span class="s2"> were &quot;</span> <span class="o">+</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span>            <span class="s2">&quot;supplied.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">63</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_instance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span> <span class="n">DirectOrPersistentSolver</span><span class="o">.</span><span class="n">_presolve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>

<span class="nn">File ~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pyomo/solvers/plugins/solvers/mosek_direct.py:180,</span> in <span class="ni">MOSEKDirect._set_instance</span><span class="nt">(self, model, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">178</span> <span class="k">def</span> <span class="nf">_set_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="o">=</span><span class="p">{}):</span>
<span class="g g-Whitespace">    </span><span class="mi">179</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_range_constraints</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">180</span>     <span class="nb">super</span><span class="p">(</span><span class="n">MOSEKDirect</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_set_instance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">181</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_pyomo_cone_to_solver_cone_map</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">182</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_solver_cone_to_pyomo_cone_map</span> <span class="o">=</span> <span class="n">ComponentMap</span><span class="p">()</span>

<span class="nn">File ~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pyomo/solvers/plugins/solvers/direct_or_persistent_solver.py:176,</span> in <span class="ni">DirectOrPersistentSolver._set_instance</span><span class="nt">(self, model, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">173</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">IBlock</span><span class="p">,</span> <span class="n">Block</span><span class="p">,</span> <span class="n">_BlockData</span><span class="p">)):</span>
<span class="g g-Whitespace">    </span><span class="mi">174</span>     <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;The problem instance supplied to the </span><span class="si">{0}</span><span class="s2"> plugin &quot;</span> \
<span class="g g-Whitespace">    </span><span class="mi">175</span>           <span class="s2">&quot;&#39;_presolve&#39; method must be a Model or a Block&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<span class="ne">--&gt; </span><span class="mi">176</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyomo_model</span> <span class="o">=</span> <span class="n">model</span>
<span class="g g-Whitespace">    </span><span class="mi">178</span> <span class="bp">self</span><span class="o">.</span><span class="n">_symbolic_solver_labels</span> <span class="o">=</span> <span class="n">kwds</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;symbolic_solver_labels&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_symbolic_solver_labels</span><span class="p">)</span>

<span class="ne">ValueError</span>: The problem instance supplied to the &lt;class &#39;pyomo.solvers.plugins.solvers.mosek_direct.MOSEKDirect&#39;&gt; plugin &#39;_presolve&#39; method must be a Model or a Block
</pre></div>
</div>
</div>
</div>
</section>
<section id="bibliographic-notes">
<h2>Bibliographic Notes<a class="headerlink" href="#bibliographic-notes" title="Permalink to this heading">#</a></h2>
<p>The development of support vector machines is largely attributed to Vladimir Vapnik and colleagues at AT&amp;T Bell Laboratories during the 1990’s. The seminal papers are highly readable and entry points to the literature.</p>
<blockquote>
<div><p>Boser, B. E., Guyon, I. M., &amp; Vapnik, V. N. (1992, July). A training algorithm for optimal margin classifiers. In Proceedings of the fifth annual workshop on Computational learning theory (pp. 144-152).  <a class="reference external" href="https://dl.acm.org/doi/10.1145/130385.130401">https://dl.acm.org/doi/10.1145/130385.130401</a></p>
</div></blockquote>
<blockquote>
<div><p>Cortes, C., &amp; Vapnik, V. (1995). Support-vector networks. Machine learning, 20(3), 273-297. <a class="reference external" href="https://link.springer.com/content/pdf/10.1007/bf00994018.pdf">https://link.springer.com/content/pdf/10.1007/bf00994018.pdf</a></p>
</div></blockquote>
<p>Support vector machines are a widely used method for supervised machine learning and described in tutorial blog postings and trade journal articles. Representative examples include</p>
<blockquote>
<div><p>Sachin, D. N. (2020). Support Vector Machines with Amazon Food Reviews <a class="reference external" href="https://medium.com/analytics-vidhya/support-vector-machines-with-amazon-food-reviews-9fe0428e09ef">https://medium.com/analytics-vidhya/support-vector-machines-with-amazon-food-reviews-9fe0428e09ef</a></p>
</div></blockquote>
<blockquote>
<div><p><a class="reference external" href="http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/">http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/</a></p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>

<span class="k">class</span> <span class="nc">LinearSvmModel</span><span class="p">(</span><span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y_train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambd</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Param</span><span class="p">(</span><span class="n">mutable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">initialize</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        
        <span class="c1"># use dataframe columns and index to index vars and constraints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">initialize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">initialize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        
        <span class="c1"># decision variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wp</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wn</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
        
        <span class="nd">@self</span><span class="o">.</span><span class="n">Expression</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">wp</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">wn</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
        
        <span class="nd">@self</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">lasso</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambd</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wp</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">wn</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">)</span>
        
        <span class="nd">@self</span><span class="o">.</span><span class="n">Constraint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">hingeloss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
            
    <span class="k">def</span> <span class="nf">svm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;cbc&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambd</span> <span class="o">=</span> <span class="n">lambd</span>
        <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="n">solver</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">LinearSvm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks/05"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="markowitz_portfolio.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Markowitz portfolio optimization</p>
      </div>
    </a>
    <a class="right-next"
       href="refinery-production.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Extra material: Refinery production and shadow pricing</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-classification">Binary Classification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-set">The Data Set</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#read-data">Read data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#select-features-and-training-sets">Select features and training sets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-machines-svm">Support vector machines (SVM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-linear-svm-classifier">A linear SVM classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-metrics">Performance metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-linear-optimization-model-to-train-a-linear-svm">A linear optimization model to train a linear SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyomo-implementation">Pyomo implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-conic-optimization-model-for-a-linear-svm">A conic optimization model for a linear SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#primal-formulation">Primal formulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dual-formulation">Dual formulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyomo-implementation-of-the-conic-dual">Pyomo implementation of the conic dual</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-kernelized-svm">A kernelized SVM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#full-dataset">Full Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Pyomo Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-svm-dual">The SVM Dual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliographic-notes">Bibliographic Notes</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The MO Book Group
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>