
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Support Vector Machines for Binary Classifcation &#8212; Companion Notebooks for Data-Driven Mathematical Optimization in Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6. Conic Optimization" href="../06/06.00.html" />
    <link rel="prev" title="Minimum Risk-Free Rate of Return" href="farkas-lemma.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-DVQ7NZ8CYZ"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-DVQ7NZ8CYZ');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo-02.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Companion Notebooks for Data-Driven Mathematical Optimization in Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Data-Driven Mathematical Optimization in Python
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/01.00.html">
   1. Mathematical Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/alice-rose.html">
     Alice’s Rose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/Pop-Up-Shop.html">
     Scenario Analysis: Pop Up Shop
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/02.00.html">
   2. Linear Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/lad-regression.html">
     Least Absolute Deviation (LAD) Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/lad-regression-wine-quality.html">
     Predicting Wine Quality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/making-the-best-of-the-worst.html">
     Making the Best of the Worst
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/mad-portfolio-optimization.html">
     MAD Portfolio Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/fractional-bim.html">
     Fractional BIM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/large-example-chapter-2.html">
     Caroline’s raw material planning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03/03.00.html">
   3. Mixed Integer Linear Programming
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/cryptarithms.html">
     Cryptarithms: Send More Money
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/strip-packing.html">
     Strip Packing: Placing Boxes on a Shelf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/simple-production-model-gdp.html">
     Production Model with Disjuncts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/recharging-electric-vehicle.html">
     Recharging Strategy for an Electric Vehicle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/Shift-Scheduling.html">
     Shift Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/machine-scheduling.html">
     Machine Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/job-shop-scheduling.html">
     Job Shop Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/maintenance-planning.html">
     Maintenance Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/large-example-chapter-3.html">
     BIM Production
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04/04.00.html">
   4. Network Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/dina-tables-and-variations.html">
     Dina’s table seating arrangements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/Transportation.html">
     Transportation and Allocation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/forex-arbitrage.html">
     Forex Arbitrage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/cryptocurrency-arbitrage.html">
     Crypto Currency Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/shortest-path-road-networks.html">
     Computing a real life shortest path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/complete-example-ch4-power-network.html">
     Energy dispatch problem
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="05.00.html">
   5. Convex Optimization
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="milk-pooling.html">
     Pooling and Blending
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="markowitz-portfolio.html">
     Markowitz Portfolio Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bilinear-relaxations.html">
     McCormick Envelopes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="refinery-production.html">
     Refinery Production and Shadow Pricing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="detecting-change.html">
     Detecting Change
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="farkas-lemma.html">
     Minimum Risk-Free Rate of Return
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Support Vector Machines for Binary Classifcation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/06.00.html">
   6. Conic Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/economic-order-quantity.html">
     Economic Order Quantity
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07/07.00.html">
   7. Accounting for Uncertainty: Optimization Meets Reality
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/Caroline-robustness-analysis.html">
     Caroline on robust steroids
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08/08.00.html">
   8. Robust Optimization - Single Stage Problems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/ef-robust-optimization.html">
     Companion notebook to EF’s training on optimization with data uncertainty
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09/09.00.html">
   9. Stochastic Optimization - Single Stage Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10/10.00.html">
   10. Robust Optimization - Two Stage Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../11/11.00.html">
   11. Stochastic Optimization - Two Stage Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyomo_style_guide.html">
   Pyomo Style Guide
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jckantor/MO-book/main?urlpath=tree/notebooks/05/svm-linear.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jckantor/MO-book/blob/main/notebooks/05/svm-linear.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/notebooks/05/svm-linear.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliographic-notes">
   Bibliographic Notes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binary-classification">
   Binary Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-data-set">
   The Data Set
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-data">
     Read data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#select-features-and-training-sets">
     Select features and training sets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-support-vector-machines-svm">
   Linear Support Vector Machines (SVM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-formulation-of-linear-svm">
   Alternative Formulation of Linear SVM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reformulation-as-a-conic-program">
     Reformulation as a conic program
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyomo-implementation">
   Pyomo Implementation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-svm-dual">
   The SVM Dual
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Support Vector Machines for Binary Classifcation</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliographic-notes">
   Bibliographic Notes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binary-classification">
   Binary Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-data-set">
   The Data Set
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-data">
     Read data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#select-features-and-training-sets">
     Select features and training sets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-support-vector-machines-svm">
   Linear Support Vector Machines (SVM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-formulation-of-linear-svm">
   Alternative Formulation of Linear SVM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reformulation-as-a-conic-program">
     Reformulation as a conic program
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyomo-implementation">
   Pyomo Implementation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-svm-dual">
   The SVM Dual
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="support-vector-machines-for-binary-classifcation">
<h1>Support Vector Machines for Binary Classifcation<a class="headerlink" href="#support-vector-machines-for-binary-classifcation" title="Permalink to this headline">#</a></h1>
<p>(NEEDS TO BE REWRITTEN FOR CONSISTENCY WITH FINAL VERSION OF THE NOTEBOOK).</p>
<p>Creating binary classifiers from sample data is an example of supervised machine learning. This notebook shows how to create a class of binary classifiers  known as support vector machines (SVM) from sample data using linear, quadratic, and conic programming. The first implementation produces linear support vector machines that separates the “feature space” with a hyperplane. The  implementation uses a dual formulation that extends naturally to non-linear classification.</p>
<p>Like many machine learning techniques based on regression, an SVM classifier can be computed from the solution to an optimization problem. The use of modeling languages and general purpose solvers can support small</p>
<p>The dual optimization problem is the basis for a second implementation. A technical feature of the dual problem extends support vector machines to nonlinear classifiers that have proven highly successful in a wide range of applications.</p>
<section id="bibliographic-notes">
<h2>Bibliographic Notes<a class="headerlink" href="#bibliographic-notes" title="Permalink to this headline">#</a></h2>
<p>The development of support vector machines is largely attributed to Vladimir Vapnik and colleagues at AT&amp;T Bell Laboratories during the 1990’s. The seminal papers are highly readable and entry points to the literature.</p>
<blockquote>
<div><p>Boser, B. E., Guyon, I. M., &amp; Vapnik, V. N. (1992, July). A training algorithm for optimal margin classifiers. In Proceedings of the fifth annual workshop on Computational learning theory (pp. 144-152).  <a class="reference external" href="https://dl.acm.org/doi/10.1145/130385.130401">https://dl.acm.org/doi/10.1145/130385.130401</a></p>
</div></blockquote>
<blockquote>
<div><p>Cortes, C., &amp; Vapnik, V. (1995). Support-vector networks. Machine learning, 20(3), 273-297. <a class="reference external" href="https://link.springer.com/content/pdf/10.1007/bf00994018.pdf">https://link.springer.com/content/pdf/10.1007/bf00994018.pdf</a></p>
</div></blockquote>
<p>Support vector machines are a widely used method for supervised machine learning and described in tutorial blog postings and trade journal articles. Representative examples include</p>
<blockquote>
<div><p>Sachin, D. N. (2020). Support Vector Machines with Amazon Food Reviews <a class="reference external" href="https://medium.com/analytics-vidhya/support-vector-machines-with-amazon-food-reviews-9fe0428e09ef">https://medium.com/analytics-vidhya/support-vector-machines-with-amazon-food-reviews-9fe0428e09ef</a></p>
</div></blockquote>
<blockquote>
<div><p><a class="reference external" href="http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/">http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/</a></p>
</div></blockquote>
</section>
<section id="binary-classification">
<h2>Binary Classification<a class="headerlink" href="#binary-classification" title="Permalink to this headline">#</a></h2>
<p>Binary classifiers are functions that answer questions like “does this medical test indicate disease?”, “will that customer like this movie?”, “does this photo contain the image of a car?”, or “is this banknote authentic or counterfeit?” The answer is based on values of “features” that may include physical measurements, values representing color of image pixels, data collected from a web page.  Depending on the application requirements, classifiers can be tuned for precision (meaning few false positives), recall (meaning few false negatives), or some trade-off between these qualities.</p>
<ul class="simple">
<li><p><strong>Precision</strong>. The number of real positives divided by the number of predicted positives. High precision implies a low false positive rate.</p></li>
<li><p><strong>Recall</strong>. The number of real positives divided by number of actual positives. High recall test implies a low false negative rate.</p></li>
</ul>
<p>Consider, for example, an device that rejects counterfeit banknotes for a vending machine. A false positive would mean the vending machine would rejects a genuine banknote which would be frustrating to a user. Users of the vending machine, therefore, would prefer a device with high precision.</p>
<p>On the other hand, a false negative would mean the vending machine would accept a counterfeit banknote. The owner of the vending machine, therefore, would prefer a device with high recall.</p>
<p>false positive  a counterfeit banknote, clearly an undesirable outcome for the seller. The seller would be interested in high precision. A buyer, however, may be frustrated if a valid banknote is needlessly rejected by the vending machine. The buyer would be interested in high recall.</p>
<p>The challenge of developing binary classifiers is to find features, and functions to evaluate those features, that provide the precision and recall needed for a particular application.</p>
</section>
<section id="the-data-set">
<h2>The Data Set<a class="headerlink" href="#the-data-set" title="Permalink to this headline">#</a></h2>
<p>The following data set contains data from a collection genuine and counterfeit banknote specimens. The data includes four continuous statistical measures obtained from the wavelet transform of banknote images and a binary variable where 0 indicates genuine and 1 indicates counterfeit.</p>
<p><a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/banknote+authentication">https://archive.ics.uci.edu/ml/datasets/banknote+authentication</a></p>
<section id="read-data">
<h3>Read data<a class="headerlink" href="#read-data" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># read data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data_banknote_authentication.txt&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;curtosis&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Banknotes&quot;</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variance</th>
      <th>skewness</th>
      <th>curtosis</th>
      <th>entropy</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.433735</td>
      <td>1.922353</td>
      <td>1.397627</td>
      <td>-1.191657</td>
      <td>0.444606</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.842763</td>
      <td>5.869047</td>
      <td>4.310030</td>
      <td>2.101013</td>
      <td>0.497103</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-7.042100</td>
      <td>-13.773100</td>
      <td>-5.286100</td>
      <td>-8.548200</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-1.773000</td>
      <td>-1.708200</td>
      <td>-1.574975</td>
      <td>-2.413450</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.496180</td>
      <td>2.319650</td>
      <td>0.616630</td>
      <td>-0.586650</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.821475</td>
      <td>6.814625</td>
      <td>3.179250</td>
      <td>0.394810</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>6.824800</td>
      <td>12.951600</td>
      <td>17.927400</td>
      <td>2.449500</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="select-features-and-training-sets">
<h3>Select features and training sets<a class="headerlink" href="#select-features-and-training-sets" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create training and validation test sets</span>
<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">]</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;genuine&quot;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;counterfeit&quot;</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span>


<span class="n">plot_Xy</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:xlabel=&#39;variance&#39;, ylabel=&#39;skewness&#39;&gt;
</pre></div>
</div>
<img alt="../../_images/svm-linear_7_1.png" src="../../_images/svm-linear_7_1.png" />
</div>
</div>
</section>
</section>
<section id="linear-support-vector-machines-svm">
<h2>Linear Support Vector Machines (SVM)<a class="headerlink" href="#linear-support-vector-machines-svm" title="Permalink to this headline">#</a></h2>
<p>A linear support vector machine is a binary classifier that uses a linear expression to determine the classification.</p>
<div class="math notranslate nohighlight">
\[y = \text{sgn}\ ( w^\top x + b)\]</div>
<p>where <span class="math notranslate nohighlight">\(w\in \mathbb{R}^p\)</span> is a set of coefficients and <span class="math notranslate nohighlight">\(w^\top x\)</span> is the dot product. In effect, the linear function divides the feature space <span class="math notranslate nohighlight">\(\mathbb{R}^p\)</span> with a hyperplane specified by <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>A training or validation set consists of <span class="math notranslate nohighlight">\(n\)</span> observations <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> where <span class="math notranslate nohighlight">\(y_i = \pm 1\)</span> and <span class="math notranslate nohighlight">\(x_i\in\mathbb{R}^p\)</span> for <span class="math notranslate nohighlight">\(i=1, \dots, n\)</span>. The training task is to find coefficients <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span> and <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span> to achieve high precision and high recall for a validation set. All points  <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> for <span class="math notranslate nohighlight">\(i\in 1, \dots, n\)</span> in a training or validation set are successfully classified if the</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i (w^\top x_i + b) &amp; &gt; 0 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\]</div>
<p>The strict inequality can be replaced by</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i (w^\top x_i + b) &amp; \geq 1 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\]</div>
<p>which defines a <strong>hard-margin</strong> classifier where the size of the margin is determined by the scale of <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>. The sample data displayed above shows it is not always possible to perfectly separate a data set into two classes. For that reason a <strong>soft-margin</strong> classifier is defined by slack variables <span class="math notranslate nohighlight">\(z_i \geq 0\)</span></p>
<div class="math notranslate nohighlight">
\[y_i (w^\top x_i + b) \geq 1 - z_i \]</div>
<p>For parameters <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>, every point that satisfies the constraint with <span class="math notranslate nohighlight">\(z_i = 0\)</span> is correctly classified with a hard margin ??? from the separating hyperplane. Points where <span class="math notranslate nohighlight">\(0 &lt; z_i &lt; 1\)</span> will also be correctly classified. Point with slack variable <span class="math notranslate nohighlight">\(z_i &gt; 1\)</span> will be misclassified.</p>
<p>Given parameters <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>, the <strong>hinge-loss</strong> function is defined as</p>
<div class="math notranslate nohighlight">
\[\ell(x, y) = \left(1 - y(w^\top x + b)\right)_+\]</div>
<p>using the notation <span class="math notranslate nohighlight">\(\left(z\right)_+ = \max(0, z)\)</span>.</p>
<p>The hinge-loss function has properties that make it useful fitting linear support vector machine.  For a properly classified point the hinge-loss will be less than one but never smaller than zero. For a mis-classified point, however, the hinge-loss function is greater than one and will grows in proportion to how far away the feature vector is from the separation plane. Minimizing the sum of hinge-loss functions locates hyperplane a that trades off between a margin for correctly classified points and minimizing the distance between the hyperplane and mis-classified points.</p>
<p>One approach to fitting a linear SVM is to assign a regularization term for <span class="math notranslate nohighlight">\(w\)</span>. In most formulations a norm <span class="math notranslate nohighlight">\(\|w\|\)</span> is used for regularization, commonly a sum of squares such as <span class="math notranslate nohighlight">\(\|w\|_2^2\)</span>. Another choice is <span class="math notranslate nohighlight">\(\|w\|_1\)</span> which, similar to Lasso regression, may result in sparse weighting vectors <span class="math notranslate nohighlight">\(w\)</span> indicating which elements of the feature vector can be neglected for classification purpose. These considerations result i the objective function</p>
<div class="math notranslate nohighlight">
\[\min_{w, b}\left[ \frac{1}{n}\sum_{i=1}^n \left(1 - y_i(w^\top x_i + b)\right)_+ + \lambda \|w\|_1\right]\]</div>
<p>which can be solved by linear programming.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{z, w, b}\ &amp; \frac{1}{n}  \sum_{i=1}^n z_i + \lambda \|w\|_1 \\
\text{s.t.}\qquad z_i &amp; \geq 1 - y_i(w^\top x_i + b) &amp; \forall i = 1, 2, \dots, n \\
z_i &amp; \geq 0 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\end{split}\]</div>
<p>This is the primal optimization problem in decision variables <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span>, <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span>, and <span class="math notranslate nohighlight">\(z\in\mathbb{R}^n\)</span>, a total of <span class="math notranslate nohighlight">\(n + p + 1\)</span> unknowns with <span class="math notranslate nohighlight">\(2n\)</span> constraints.</p>
</section>
<section id="alternative-formulation-of-linear-svm">
<h2>Alternative Formulation of Linear SVM<a class="headerlink" href="#alternative-formulation-of-linear-svm" title="Permalink to this headline">#</a></h2>
<p>The standard formulation of a linear support vector machine uses training sets <span class="math notranslate nohighlight">\(p\)</span>-element feature vectors <span class="math notranslate nohighlight">\(x_i\in\mathbb{R}^p\)</span>, a classification for those vectors, <span class="math notranslate nohighlight">\(y_i = \pm 1\)</span> and a classifier defined by <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span> and <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span></p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y &amp; = \text{sgn}(w^\top x + b)
\end{align*}
\]</div>
<p>The parameter <span class="math notranslate nohighlight">\(b\)</span> is an annoying term that unnecessarily clutters the presentation and derivations. As an alternative formulation, consider an augmented feature vector <span class="math notranslate nohighlight">\(\bar{x} = (1, x) \in \mathbb{R}^{p+1}\)</span> and parameter vector <span class="math notranslate nohighlight">\(\bar{w} = (b, w) \in \mathbb{R}^{p+1}\)</span>. The linear SVM machine then becomes</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y &amp; = \text{sgn}(\bar{w}^\top \bar{x})
\end{align*}
\]</div>
<p>If a hard-margin classifier exists for a training or validation set <span class="math notranslate nohighlight">\((\bar{x}_i, y_i)\)</span> for <span class="math notranslate nohighlight">\(i=1, \dots, n\)</span> then it would satisfy</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i \bar{w}^\top \bar{x}_i &amp; \geq 1 &amp; \forall i \in 1, 2, \dots, n
\end{align*}
\]</div>
<p>The separating hyperplane consists of all points normal to <span class="math notranslate nohighlight">\(\bar{w}\)</span>. The distance between <span class="math notranslate nohighlight">\(x_i\)</span> and the separating  hyperplane is</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{w}^\top \bar{x}_i}{\|\bar{w}\|}\]</div>
<p>The soft-margin classifier is found by solving</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min \frac{1}{2} \|\bar{w}\|_2^2 &amp; + \frac{c}{n}\sum_{i=1}^n z_i \\
\text{s.t.} \qquad z_i &amp; \geq 1 - y_i \bar{w}^\top \bar{x}_i &amp; \forall i = 1, 2, \dots, n \\
z_i &amp; \geq 0 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\end{split}\]</div>
<p>Recasting as a conic program</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r + \frac{c}{n} 1^\top z\\
\text{s. t.}\qquad &amp; (r, 1, \bar{w}) \in Q_r^{3 + p} \\
&amp; z + F \bar{w} \geq 1  \\
&amp; z \geq 0 \\
\end{align*}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.kernel</span> <span class="k">as</span> <span class="nn">pmo</span>

<span class="k">def</span> <span class="nf">svm_conic_primal</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">())</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">primal</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">+</span> <span class="p">(</span><span class="n">c</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)))</span>

    <span class="n">m</span><span class="o">.</span><span class="n">qr</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">)),</span> <span class="n">lb</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">pmo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;mosek_direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">m</span>

<span class="n">c</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="o">%</span><span class="k">timeit</span> svm_conic_primal(X_train, y_train, c)
<span class="n">m</span> <span class="o">=</span> <span class="n">svm_conic_primal</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

<span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>

<span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
    
<span class="nb">print</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>406 ms ± 28.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
0.07200641543306915
0 0.0331810447205884
1 -0.3611410899436258
2 -0.11175402874221647

5 1.359091455501977
7 1.2541948152030387
20 1.602091538685219
21 1.2276046199107682
22 1.1574310326317327
24 1.0917509587731185
32 2.2290501119093706
42 1.0386475913247217
43 1.0384308976799776
45 1.8244816976858167
58 1.7883898309503
62 1.0427543058758248
67 1.8430866878614267
69 1.1047100674832462
71 1.8130596121470242
74 1.5690185059698254
102 1.0531610371681452
111 1.8235759493630794
113 1.0107042435600313
121 1.432285413069027
124 2.267786205170612
125 1.2342113978132807
138 1.2102554184223056
144 1.3036197862429748
150 1.1217697273532978
157 1.4571654611085683
160 1.7639750959190568
181 1.2102554184223056
183 1.05557846768545
185 2.0346337087618496
209 1.661344880925296
218 1.3487766024310917
222 1.4121665003659019
226 1.3315309829174216
230 1.8023391890442768
241 1.1582638425783283
253 1.9519048309189584
258 1.0355855958987124
277 1.2642723323753262
289 1.4789524924481483
301 1.3432715966847313
305 1.035699014980986
312 1.0884393347445878
318 1.4121801946963188
323 1.452197698832976
327 1.4121801946963188
334 1.0432283063880219
338 1.227274667709557
339 1.2212767912651679
342 1.1217697273532978
343 1.8135538860761893
355 1.4330108799524812
358 1.6700172597934668
364 1.1654489942440855
366 1.0761153470046612
385 1.0495581778102003
391 1.133130178262324
395 1.2297396413080275
397 1.134150218309902
403 1.4804027845131271
405 1.5262921512077057
410 1.6212011866057126
411 1.1061727618291437
423 1.182796218652375
450 1.1217697273532978
454 1.210267003969772
467 1.2446107716987251
474 1.655434889855699
479 1.9654350902634017
489 1.286370014950445
499 1.5411954035538478
509 1.0288997339768262
513 1.6422500284589816
518 1.19763726661695
533 1.1038130526951997
537 1.3927596022211253
541 1.89357390451466
546 1.4121801946963188
564 1.6723996178580463
574 1.5631956697081686
591 1.2090552331013948
594 1.3612361857456468
597 1.2102554184223056
615 1.2735169515759825
618 1.5798220230311961
622 1.426424199648328
633 1.8584090058821867
635 1.218385912311092
648 1.7303055705548214
650 1.3168507807924668
653 1.1131891296534144
655 1.3682874940948182
670 1.3996721903867562
691 1.9137806972644846
693 2.007731917815399
696 1.00899549163658
704 1.2289948145047886
707 1.0948787735300023
722 1.66959736253879
760 2.1465439101839903
790 1.9072659694288892
792 1.8964504261863506
796 1.0385830728585541
809 1.2102554184223056
814 1.0135981612017484
819 1.704296539067794
823 1.0658548692075724
841 1.281818472008897
847 1.1075308587503554
850 1.5417172943193593
851 1.6314500844276902
852 1.1112233201565995
859 1.113353271460813
876 1.775484046937385
884 1.5607616538358484
905 1.2691258408718222
907 1.0463593331280514
908 1.1249849075621898
910 1.1316441180527275
925 1.3627662922029564
929 1.6246855488298424
930 1.5264403239579865
932 1.011011533884714
954 1.6194142870984714
959 1.2419813316217687
965 1.4121801946963188
970 1.9126585303456838
986 1.8463287282079883
989 1.0214518833063193
990 1.0110812073435673
1002 1.1756338053816189
1017 1.458220699913437
1020 1.1404042673556207
1028 1.135794001684137
1031 1.2792932149191496
1033 1.0171503288145374
1040 1.074383891374651
1041 1.6418221591441693
1046 1.4276296199350316
1050 1.1533785854834242
1064 1.3925470762114434
1081 1.7454983106310218
1082 1.6349083265644972
1088 1.7780711236497235
1091 1.2014027426775822
</pre></div>
</div>
</div>
</div>
<p>Creating a differentiable Lagrangian with dual factors <span class="math notranslate nohighlight">\(\alpha_i\)</span> for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>, the task is to find saddle points of</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L} &amp; = \frac{1}{2} \|\bar{w}\|_2^2 + \frac{c}{n}\sum_{i=1}^n z_i + \sum_{i=1}^n \alpha_i (1 - y_i \bar{w}^\top \bar{x}_i - z_i) + \sum_{i=1}^n \beta_i (-z_i) \\
\end{align*}
\end{split}\]</div>
<p>Taking derivatives with respect to the primal variables</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial \mathcal{L}}{\partial z_i} &amp; = \frac{c}{n} - \alpha_i - \beta_i = 0 \implies 0 \leq \alpha_i \leq \frac{c}{n}\\
\frac{\partial \mathcal{L}}{\partial \bar{w}} &amp; = \bar{w}  - \sum_{i=1}^n \alpha_i y_i \bar{x}_i = 0 \implies  \bar{w} = \sum_{i=1}^n \alpha_i y_i \bar{x}_i \\
\end{align*}
\end{split}\]</div>
<p>resulting in the dual formulation</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\max_{\alpha_i}\ &amp;  \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( \bar{x}_i^\top \bar{x}_j ) \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>Rearranging as a standard quadratic program in <span class="math notranslate nohighlight">\(n\)</span> variables <span class="math notranslate nohighlight">\(\alpha_i\)</span> for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{\alpha_i}\ &amp; \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( \bar{x}_i^\top \bar{x}_j ) -  \sum_{i=1}^n \alpha_i \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>The <span class="math notranslate nohighlight">\(n \times n\)</span> <strong>Gram matrix</strong> is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}G = \begin{bmatrix} 
\bar{x}_1^\top \bar{x}_1 &amp; \dots &amp; \bar{x}_1^\top \bar{x}_n \\ 
\vdots &amp; \ddots &amp; \vdots \\ 
\bar{x}_n^\top \bar{x}_1 &amp; \dots &amp; \bar{x}_n^\top \bar{x}_n 
\end{bmatrix}\end{split}\]</div>
<p>where each entry is dot product of two vectors <span class="math notranslate nohighlight">\(\bar{x}_i, \bar{x}_j \in \mathbb{R}^{p+1}\)</span>.</p>
<p>Compared to the primal, the dual formulation has reduced to the number of decision variables from <span class="math notranslate nohighlight">\(n + p + 1\)</span> to <span class="math notranslate nohighlight">\(n\)</span>. But this has come with the significant penalty of introducing a dense matrix with <span class="math notranslate nohighlight">\(n^2\)</span> coefficients and potential processing time of order <span class="math notranslate nohighlight">\(n^3\)</span>. For large training sets, <span class="math notranslate nohighlight">\(n\sim 10^4-10^5\)</span> this is prohibitively expensive.</p>
<section id="reformulation-as-a-conic-program">
<h3>Reformulation as a conic program<a class="headerlink" href="#reformulation-as-a-conic-program" title="Permalink to this headline">#</a></h3>
<p>Introduce the <span class="math notranslate nohighlight">\(n \times (p+1)\)</span> matrix <span class="math notranslate nohighlight">\(F\)</span> defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}F = \begin{bmatrix} y_1 \bar{x}_1^\top \\ y_2 \bar{x}_2^\top \\ \vdots \\ y_n \bar{x}_n^\top \end{bmatrix}\end{split}\]</div>
<p>Then introducing an additional decision variabl <span class="math notranslate nohighlight">\(r \geq 0\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r - 1^\top \alpha\\
\text{s. t.}\qquad &amp; \alpha^\top F F^\top \alpha \leq 2 r \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>Using the notation <span class="math notranslate nohighlight">\(\mathcal{Q}^m_r\)</span> for a rotated quadratic cone (for example, see <a class="reference external" href="https://docs.mosek.com/modeling-cookbook/cqo.html#equation-eq-sec-qo-modeling-qset2">https://docs.mosek.com/modeling-cookbook/cqo.html#equation-eq-sec-qo-modeling-qset2</a>)</p>
<div class="math notranslate nohighlight">
\[\mathcal{Q}^m_r = \{z\in\mathbb{R}^m | 2z_1z_2 \geq z_3^2 + \cdots + z_m^2,\ z_1, z_2 \geq 0 \}\]</div>
<p>The quadratic constraint is reformulated as a rotated quadratic cone</p>
<div class="math notranslate nohighlight">
\[\frac{1}{2}\alpha^\top F F^\top \alpha \leq r \iff (r, 1, F^\top \alpha) \in Q_r^{3 + p}\]</div>
<p>The reformulated dual problem is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r - 1^\top \alpha\\
\text{s. t.}\qquad &amp; (r, 1, F^\top \alpha) \in Q_r^{3 + p} \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>The conic reformulation eliminates the need to store an <span class="math notranslate nohighlight">\(n\times n\)</span> Gram matrix.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r - 1^\top \alpha\\
\text{s. t.}\qquad &amp; (r, 1, z) \in Q_r^{3 + p} \\
&amp; z = F^\top \alpha \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.kernel</span> <span class="k">as</span> <span class="nn">pmo</span>

<span class="k">def</span> <span class="nf">svm_conic_dual</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">c</span><span class="o">/</span><span class="n">n</span><span class="p">))</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">())</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1">#m.d[j] = pmo.linear_constraint(variables=[m.a, m.z[j]], coefficients=np.append(F[:,j], -1), rhs=0.0)</span>
        <span class="n">m</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">rhs</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">o</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)))</span>
    <span class="n">m</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
    
    <span class="n">pmo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;mosek_direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">m</span>

<span class="n">c</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="o">%</span><span class="k">timeit</span> svm_conic(X_train, y_train, c)
<span class="n">m</span> <span class="o">=</span> <span class="n">svm_conic</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="o">&gt;</span> <span class="mf">1e-7</span> <span class="ow">and</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="o">&lt;</span> <span class="n">c</span><span class="o">/</span><span class="n">n</span> <span class="o">-</span> <span class="mf">1e-7</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>393 ms ± 44.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
0.07201324288912872
40 1.4538831619299917e-07
210 2.6858783400757923e-07
292 0.0003694994962618517
511 1.4644490839692908e-07
598 0.0009113022844328891
607 5.135401782476993e-07
608 4.073621290280359e-06
620 4.414124384720946e-06
751 0.0009114686099036929
896 0.0009114562027052138
1003 1.0018716489473188e-06
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="pyomo-implementation">
<h2>Pyomo Implementation<a class="headerlink" href="#pyomo-implementation" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>


<span class="k">def</span> <span class="nf">svm_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">()</span>

    <span class="c1"># zero-based indexing</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">m</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wpos</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wneg</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Constraint</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">hinge_loss</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span> <span class="o">+</span> <span class="n">lambd</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">m</span><span class="o">.</span><span class="n">wpos</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">wneg</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span>
        <span class="p">)</span>

    <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;glpk&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">()</span>

    <span class="c1"># return a binary classifier</span>
    <span class="k">def</span> <span class="nf">svm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">w</span> <span class="o">@</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

    <span class="n">svm</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">w</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>

    <span class="k">return</span> <span class="n">svm</span>


<span class="c1"># create a linear SVM binary classifier</span>

<span class="o">%</span><span class="k">timeit</span> svm = svm_fit(X_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>389 ms ± 41.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">svm</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>

    <span class="n">true_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">false_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">false_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">true_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">tp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">true_pos</span><span class="p">)</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">false_pos</span><span class="p">)</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">false_neg</span><span class="p">)</span>
    <span class="n">tn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">true_neg</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;                   Test Data (n = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;                  y = 1       y = -1&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Predict y =  1    </span><span class="si">{</span><span class="n">tp</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">      </span><span class="si">{</span><span class="n">fp</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">    precision = </span><span class="si">{</span><span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Predict y = -1    </span><span class="si">{</span><span class="n">fn</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">      </span><span class="si">{</span><span class="n">tn</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2"> &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;      Recall =     </span><span class="si">{</span><span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">plot</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">w</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">b</span>
        <span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()</span>
        <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="p">[</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">xmin</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">xmax</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">5.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">true_pos</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">true_pos</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">true_neg</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">true_neg</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;true positive&quot;</span><span class="p">,</span> <span class="s2">&quot;true negative&quot;</span><span class="p">])</span>

    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">false_pos</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">false_pos</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">false_neg</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">false_neg</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;false negative&quot;</span><span class="p">,</span> <span class="s2">&quot;false_positive&quot;</span><span class="p">])</span>


<span class="n">svm</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                   Test Data (n = 275)
                  y = 1       y = -1
 Predict y =  1     102        19    precision = 0.843
 Predict y = -1      14       140 
      Recall =     0.879
</pre></div>
</div>
<img alt="../../_images/svm-linear_16_1.png" src="../../_images/svm-linear_16_1.png" />
<img alt="../../_images/svm-linear_16_2.png" src="../../_images/svm-linear_16_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_train_full</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_train_full</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_test_full</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_test_full</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># fit svm and test</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">)</span>
<span class="n">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_test_full</span><span class="p">,</span> <span class="n">y_test_full</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                   Test Data (n = 275)
                  y = 1       y = -1
 Predict y =  1     116         0    precision = 1.000
 Predict y = -1       0       159 
      Recall =     1.000
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-svm-dual">
<h2>The SVM Dual<a class="headerlink" href="#the-svm-dual" title="Permalink to this headline">#</a></h2>
<p>Creating the dual of the support vector machine will turn out to have practical consequences. Creating the dual requires a differentiable objective function. For this reason, the regularization term is changed to the 2-norm of <span class="math notranslate nohighlight">\(w\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{z, w, b}\  \frac{1}{2} \|w\|_2^2 + \frac{c}{n}  \sum_{i=1}^n z_i \\
\\
\text{s.t.}\qquad 1 - y_i(w^\top x_i + b) - z_i &amp; \leq 0 &amp; \forall i = 1, \dots, n \\
- z_i &amp; \leq 0 &amp; \forall i = 1, \dots, n
\end{align*}
\end{split}\]</div>
<p>where the regularization parameter shifted to <span class="math notranslate nohighlight">\(c\)</span>, and the constraints restated in standard form. This is a quadratic problem in <span class="math notranslate nohighlight">\(n + p + 1\)</span> variables and <span class="math notranslate nohighlight">\(2n\)</span> constraints.</p>
<p>The Lagrangian <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L} &amp; = \frac{1}{2} \|w\|_2^2 + \frac{c}{n}\sum_{i=1}^n z_i + \sum_{i=1}^n \alpha_i (1 - y_i(w^\top x_i + b) - z_i) + \sum_{i=1}^n \beta_i (-z_i) \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(2n\)</span> non-negative Lagrange multipliers <span class="math notranslate nohighlight">\(\alpha_i \geq 0\)</span> and <span class="math notranslate nohighlight">\(\beta_1 \geq 0\)</span> have been introduced for <span class="math notranslate nohighlight">\(i \in 1,\dots,n\)</span>. Intuitively, the Lagrange variables are penalty weights assigned to the inequality constraints introduced into a modified objective function. If the penalties are large enough then the constraints will be satisfied.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial \mathcal{L}}{\partial z_i} &amp; = \frac{c}{n} - \alpha_i - \beta_i = 0 \implies 0 \leq \alpha_i \leq \frac{c}{n}\\
\frac{\partial \mathcal{L}}{\partial w} &amp; = w  - \sum_{i=1}^n \alpha_i y_i x_i = 0 \implies  w = \sum_{i=1}^n \alpha_i y_i x_i \\
\frac{\partial \mathcal{L}}{\partial b} &amp; = -\sum_{i=1}^n \alpha_i y_i = 0 \implies \sum_{i=1}^n \alpha_i y_i = 0 \\
\end{align*}
\end{split}\]</div>
<p>The dual problem is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\max_{\alpha_i}\ &amp;  \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( x_i^\top x_j ) \\
\text{s. t.}\quad &amp; \sum_{i=1}^n \alpha_i y_i = 0 \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>Like the primal, the dual is a quadratic program. The dual, however, has only <span class="math notranslate nohighlight">\(n\)</span> decision variables compared to <span class="math notranslate nohighlight">\(n + p + 1\)</span> decision variables for the primal, and <span class="math notranslate nohighlight">\(n + 1\)</span> constraints compared to <span class="math notranslate nohighlight">\(2n\)</span> constraints for the primal. This reduction is significant for problems with many features (i.e, large <span class="math notranslate nohighlight">\(p\)</span>), or for large training sets (i.e., large <span class="math notranslate nohighlight">\(n\)</span>). The case of large <span class="math notranslate nohighlight">\(p\)</span> becomes important when extending SVM to nonlinear classification using kernels.</p>
<p>Note, however, that the reduced number of decision variables and constraints in the dual problem requires computing <span class="math notranslate nohighlight">\(\frac{n(n+1)}{2}\)</span> inner products <span class="math notranslate nohighlight">\((x_i^\top x_j)\)</span> for <span class="math notranslate nohighlight">\(i \leq j\)</span> and <span class="math notranslate nohighlight">\(i,j\in \mathbb{R}^n\)</span>.   The inner products can be arranged as a symmetric matrix
$<span class="math notranslate nohighlight">\(
\begin{align*}
K = [k_{i,j}] = X X^\top = \begin{bmatrix}
x_1^\top x_1 &amp; x_1^\top x_2 &amp; \dots &amp; x_1^\top x_n \\
x_2^\top x_1 &amp; x_2^\top x_2 &amp; \dots &amp; x_2^\top x_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_n^\top x_1 &amp; x_n^\top x_2 &amp; \dots &amp;  x_n^\top x_n \\
\end{bmatrix}
\end{align*}
\)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n\times p}\)</span> is the matrix formed by the <span class="math notranslate nohighlight">\(n\)</span> feature vectors <span class="math notranslate nohighlight">\(x_i\)</span> for <span class="math notranslate nohighlight">\(i=1, 2, \dots, n\)</span>. The symmetry of <span class="math notranslate nohighlight">\(K\)</span>, which is known as the Gram matrix (or Grammian) is a consequence of the symmetry of the inner product for real number spaces.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
w^* &amp; = \sum_{i=1}^n \alpha_i^* y_i x_i \\
b^* &amp; = y_k - (w^*)^\top x_k &amp; \text{for any }k\ni 0 &lt; \alpha_k &lt; \frac{c}{n} \\
\end{align*}
\end{split}\]</div>
<p>which can be written entirely in terms of the inner product.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
w^* &amp; = \sum_{i=1}^n \alpha_i^* y_i x_i \\
b^* &amp; = y_k - \sum_{i=1}^n \alpha_i^* y_i x_i^\top x_k &amp; \text{for any }k\ni 0 &lt; \alpha_k &lt; \frac{c}{n} 
\end{align*}
\end{split}\]</div>
<p>Given a value for the feature vector <span class="math notranslate nohighlight">\(x\in\mathbb{R}^p\)</span>, the classifier <span class="math notranslate nohighlight">\(\hat{y} = \text{sgn}\ \left((w^*)^\top x + b^* \right)\)</span> is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\hat{y} &amp; = \text{sgn}\ \left( y_k + \sum_{i=1}^n \alpha_i^* y_i x^\top_i (x - x_k) \right)\\
\end{align*}
\end{split}\]</div>
<p>This is result has important consequences. The key point is that is that the dual optimization problem can be solved with knowledge of the inner products appearing in the Gram matrix <span class="math notranslate nohighlight">\(K\)</span>, and the resulting classifier needs only inner products of training set data with the difference <span class="math notranslate nohighlight">\(x - x_k\)</span> for some <span class="math notranslate nohighlight">\(k\)</span> found in the optimization calculation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>


<span class="k">def</span> <span class="nf">svm_dual_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">()</span>

    <span class="n">X_np</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

    <span class="n">K</span> <span class="o">=</span> <span class="n">X_np</span> <span class="o">@</span> <span class="n">X_np</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># zero-based indexing</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Constraint</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">sumya</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">maximize</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span>
        <span class="p">)</span>

    <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">svm</span><span class="p">():</span>
        <span class="k">pass</span>

    <span class="k">return</span> <span class="n">svm</span>


<span class="c1"># create a linear SVM binary classifier</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="nn">Input In [8],</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

<span class="nn">File ~/opt/anaconda3/lib/python3.9/site-packages/pyomo/solvers/plugins/solvers/direct_solver.py:119,</span> in <span class="ni">DirectSolver.solve</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">114</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> 
<span class="g g-Whitespace">    </span><span class="mi">116</span>     <span class="c1"># we&#39;re good to go.</span>
<span class="g g-Whitespace">    </span><span class="mi">117</span>     <span class="n">initial_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">119</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_presolve</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">121</span>     <span class="n">presolve_completion_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">122</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_timing</span><span class="p">:</span>

<span class="nn">File ~/opt/anaconda3/lib/python3.9/site-packages/pyomo/solvers/plugins/solvers/direct_solver.py:62,</span> in <span class="ni">DirectSolver._presolve</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span>     <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;The </span><span class="si">{0}</span><span class="s2"> plugin method &#39;_presolve&#39; must be supplied a single problem instance - </span><span class="si">{1}</span><span class="s2"> were &quot;</span> <span class="o">+</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span>            <span class="s2">&quot;supplied.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">62</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_instance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span> <span class="n">DirectOrPersistentSolver</span><span class="o">.</span><span class="n">_presolve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>

<span class="nn">File ~/opt/anaconda3/lib/python3.9/site-packages/pyomo/solvers/plugins/solvers/mosek_direct.py:179,</span> in <span class="ni">MOSEKDirect._set_instance</span><span class="nt">(self, model, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span> <span class="k">def</span> <span class="nf">_set_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="o">=</span><span class="p">{}):</span>
<span class="g g-Whitespace">    </span><span class="mi">178</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_range_constraints</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">179</span>     <span class="nb">super</span><span class="p">(</span><span class="n">MOSEKDirect</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_set_instance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">180</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_pyomo_cone_to_solver_cone_map</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">181</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_solver_cone_to_pyomo_cone_map</span> <span class="o">=</span> <span class="n">ComponentMap</span><span class="p">()</span>

<span class="nn">File ~/opt/anaconda3/lib/python3.9/site-packages/pyomo/solvers/plugins/solvers/direct_or_persistent_solver.py:175,</span> in <span class="ni">DirectOrPersistentSolver._set_instance</span><span class="nt">(self, model, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">172</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">IBlock</span><span class="p">,</span> <span class="n">Block</span><span class="p">,</span> <span class="n">_BlockData</span><span class="p">)):</span>
<span class="g g-Whitespace">    </span><span class="mi">173</span>     <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;The problem instance supplied to the </span><span class="si">{0}</span><span class="s2"> plugin &quot;</span> \
<span class="g g-Whitespace">    </span><span class="mi">174</span>           <span class="s2">&quot;&#39;_presolve&#39; method must be a Model or a Block&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<span class="ne">--&gt; </span><span class="mi">175</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">176</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyomo_model</span> <span class="o">=</span> <span class="n">model</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span> <span class="bp">self</span><span class="o">.</span><span class="n">_symbolic_solver_labels</span> <span class="o">=</span> <span class="n">kwds</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;symbolic_solver_labels&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_symbolic_solver_labels</span><span class="p">)</span>

<span class="ne">ValueError</span>: The problem instance supplied to the &lt;class &#39;pyomo.solvers.plugins.solvers.mosek_direct.MOSEKDirect&#39;&gt; plugin &#39;_presolve&#39; method must be a Model or a Block
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/05"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="farkas-lemma.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Minimum Risk-Free Rate of Return</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../06/06.00.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">6. Conic Optimization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The MO Book Group<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>