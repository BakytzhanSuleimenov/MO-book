
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Support Vector Machines for Binary Classification &#8212; Companion Notebooks for Data-Driven Mathematical Optimization in Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Extra material: Refinery production and shadow pricing" href="refinery-production.html" />
    <link rel="prev" title="Portfolio optimization with chance constraint" href="markowitz_portfolio_with_chance_constraint.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-DVQ7NZ8CYZ"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-DVQ7NZ8CYZ');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo-02.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Companion Notebooks for Data-Driven Mathematical Optimization in Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Data-Driven Mathematical Optimization in Python
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/01.00.html">
   1. Mathematical Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/glass-water.html">
     A motivating example: A glass of water
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/02.00.html">
   2. Linear Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/bim.html">
     BIM production
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/lad-regression.html">
     LAD Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/mad-portfolio-optimization.html">
     MAD portfolio optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/l1-regression-wine-quality.html">
     Wine quality prediction with L1 regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/bim-fractional.html">
     BIM production variants
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/multiproductionfaciliity_worstcase.html">
     Extra material: Multi-product facility production
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03/03.00.html">
   3. Mixed Integer Linear Programming
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/bim-perturbed.html">
     BIM production with perturbed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/shift-scheduling.html">
     Workforce shift scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/simple-production-model-gdp.html">
     Production model using disjunctions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/machine-scheduling.html">
     Machine Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/recharging-electric-vehicle.html">
     Recharging strategy for an electric vehicle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/bim-production-revisited.html">
     BIM production revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/cryptarithms.html">
     Extra material: Cryptarithms puzzle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/strip-packing.html">
     Extra material: Strip packing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/job-shop-scheduling.html">
     Extra material: Job shop scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/maintenance-planning.html">
     Extra material: Maintenance planning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04/04.00.html">
   4. Network Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/dinner-seat-allocation.html">
     Dinner seating arrangement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/gasoline-distribution.html">
     Gasoline distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/cryptocurrency-arbitrage.html">
     Cryptocurrency arbitrage search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/shortest-path-road-networks.html">
     Extra material: Shortest path in real life
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/power-network.html">
     Extra material: Energy dispatch problem
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="05.00.html">
   5. Convex Optimization
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="milk-pooling.html">
     Milk pooling and blending
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ols-regression.html">
     Ordinary Least Squares (OLS) Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="markowitz_portfolio_with_chance_constraint.html">
     Portfolio optimization with chance constraint
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Support Vector Machines for Binary Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="refinery-production.html">
     Extra material: Refinery production and shadow pricing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/06.00.html">
   6. Conic Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/economic-order-quantity.html">
     Economic Order Quantity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/building-insulation.html">
     Optimal Design of Multilayered Building Insulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/kelly-criterion.html">
     The Kelly Criterion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/investment-wheel.html">
     Luenberger’s Investment Wheel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/optimal-growth-portfolios.html">
     Optimal Growth Portfolios
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07/07.00.html">
   7. Accounting for Uncertainty: Optimization Meets Reality
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/fleet-assignment.html">
     Fleet assignment problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/bim-robustness-analysis.html">
     Robustness analysis of BIM production plan via simulations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08/08.00.html">
   8. Robust Optimization - Single Stage Problems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/bim-robust-optimization.html">
     Robust BIM microchip production problem
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09/09.00.html">
   9. Stochastic Optimization - Single Stage Problems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/pop-up_shop.html">
     Pop-up shop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/newsvendor.html">
     Stock optimization for seafood distribution center
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10/10.00.html">
   10. Two-Stage Problems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/ccg.html">
     Robust Production Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/airline-seating.html">
     Airline seat allocation problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/farmer.html">
     The Farmer’s Problem and Variants
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyomo_style_guide.html">
   Appendix: Pyomo style guide
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/mobook/MO-book/main?urlpath=tree/notebooks/05/svm-linear.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/mobook/MO-book/blob/main/notebooks/05/svm-linear.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/mobook/MO-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/mobook/MO-book/issues/new?title=Issue%20on%20page%20%2Fnotebooks/05/svm-linear.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/notebooks/05/svm-linear.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliographic-notes">
   Bibliographic Notes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binary-classification">
   Binary Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-data-set">
   The Data Set
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-data">
     Read data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#select-features-and-training-sets">
     Select features and training sets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-support-vector-machines-svm">
   Linear Support Vector Machines (SVM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-formulation-of-linear-svm">
   Alternative Formulation of Linear SVM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reformulation-as-a-conic-program">
     Reformulation as a conic program
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyomo-implementation">
   Pyomo Implementation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-svm-dual">
   The SVM Dual
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Support Vector Machines for Binary Classification</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliographic-notes">
   Bibliographic Notes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binary-classification">
   Binary Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-data-set">
   The Data Set
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-data">
     Read data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#select-features-and-training-sets">
     Select features and training sets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-support-vector-machines-svm">
   Linear Support Vector Machines (SVM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-formulation-of-linear-svm">
   Alternative Formulation of Linear SVM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reformulation-as-a-conic-program">
     Reformulation as a conic program
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyomo-implementation">
   Pyomo Implementation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-svm-dual">
   The SVM Dual
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="support-vector-machines-for-binary-classification">
<h1>Support Vector Machines for Binary Classification<a class="headerlink" href="#support-vector-machines-for-binary-classification" title="Permalink to this heading">#</a></h1>
<p>Creating binary classifiers from sample data is an example of supervised machine learning. This notebook shows how to create a class of binary classifiers  known as support vector machines (SVM) from sample data using linear, quadratic, and conic programming. The first implementation produces linear support vector machines that separates the “feature space” with a hyperplane. The  implementation uses a dual formulation that extends naturally to non-linear classification.</p>
<p>Like many machine learning techniques based on regression, an SVM classifier can be computed from the solution to an optimization problem. The use of modeling languages and general purpose solvers can support small</p>
<p>The dual optimization problem is the basis for a second implementation. A technical feature of the dual problem extends support vector machines to nonlinear classifiers that have proven highly successful in a wide range of applications.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># install Pyomo and solvers</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">types</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/mobook/MO-book/main/python/helper.py&quot;</span>
<span class="n">helper</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">ModuleType</span><span class="p">(</span><span class="s2">&quot;helper&quot;</span><span class="p">)</span>
<span class="n">exec</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">helper</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>

<span class="n">helper</span><span class="o">.</span><span class="n">install_pyomo</span><span class="p">()</span>
<span class="n">helper</span><span class="o">.</span><span class="n">install_mosek</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>pyomo was previously installed
mosek was previously installed
</pre></div>
</div>
</div>
</div>
<section id="bibliographic-notes">
<h2>Bibliographic Notes<a class="headerlink" href="#bibliographic-notes" title="Permalink to this heading">#</a></h2>
<p>The development of support vector machines is largely attributed to Vladimir Vapnik and colleagues at AT&amp;T Bell Laboratories during the 1990’s. The seminal papers are highly readable and entry points to the literature.</p>
<blockquote>
<div><p>Boser, B. E., Guyon, I. M., &amp; Vapnik, V. N. (1992, July). A training algorithm for optimal margin classifiers. In Proceedings of the fifth annual workshop on Computational learning theory (pp. 144-152).  <a class="reference external" href="https://dl.acm.org/doi/10.1145/130385.130401">https://dl.acm.org/doi/10.1145/130385.130401</a></p>
</div></blockquote>
<blockquote>
<div><p>Cortes, C., &amp; Vapnik, V. (1995). Support-vector networks. Machine learning, 20(3), 273-297. <a class="reference external" href="https://link.springer.com/content/pdf/10.1007/bf00994018.pdf">https://link.springer.com/content/pdf/10.1007/bf00994018.pdf</a></p>
</div></blockquote>
<p>Support vector machines are a widely used method for supervised machine learning and described in tutorial blog postings and trade journal articles. Representative examples include</p>
<blockquote>
<div><p>Sachin, D. N. (2020). Support Vector Machines with Amazon Food Reviews <a class="reference external" href="https://medium.com/analytics-vidhya/support-vector-machines-with-amazon-food-reviews-9fe0428e09ef">https://medium.com/analytics-vidhya/support-vector-machines-with-amazon-food-reviews-9fe0428e09ef</a></p>
</div></blockquote>
<blockquote>
<div><p><a class="reference external" href="http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/">http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/</a></p>
</div></blockquote>
</section>
<section id="binary-classification">
<h2>Binary Classification<a class="headerlink" href="#binary-classification" title="Permalink to this heading">#</a></h2>
<p>Binary classifiers are functions that answer questions like “does this medical test indicate disease?”, “will that customer like this movie?”, “does this photo contain the image of a car?”, or “is this banknote authentic or counterfeit?” The answer is based on values of “features” that may include physical measurements, values representing color of image pixels, data collected from a web page.  Depending on the application requirements, classifiers can be tuned for precision (meaning few false positives), recall (meaning few false negatives), or some trade-off between these qualities.</p>
<ul class="simple">
<li><p><strong>Precision</strong>. The number of real positives divided by the number of predicted positives. High precision implies a low false positive rate.</p></li>
<li><p><strong>Recall</strong>. The number of real positives divided by number of actual positives. High recall test implies a low false negative rate.</p></li>
</ul>
<p>Consider, for example, an device that rejects counterfeit banknotes for a vending machine. A false positive would mean the vending machine would rejects a genuine banknote which would be frustrating to a user. Users of the vending machine, therefore, would prefer a device with high precision.</p>
<p>On the other hand, a false negative would mean the vending machine would accept a counterfeit banknote. The owner of the vending machine, therefore, would prefer a device with high recall.</p>
<p>false positive  a counterfeit banknote, clearly an undesirable outcome for the seller. The seller would be interested in high precision. A buyer, however, may be frustrated if a valid banknote is needlessly rejected by the vending machine. The buyer would be interested in high recall.</p>
<p>The challenge of developing binary classifiers is to find features, and functions to evaluate those features, that provide the precision and recall needed for a particular application.</p>
</section>
<section id="the-data-set">
<h2>The Data Set<a class="headerlink" href="#the-data-set" title="Permalink to this heading">#</a></h2>
<p>The following data set contains data from a collection genuine and counterfeit banknote specimens. The data includes four continuous statistical measures obtained from the wavelet transform of banknote images and a binary variable where 0 indicates genuine and 1 indicates counterfeit.</p>
<p><a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/banknote+authentication">https://archive.ics.uci.edu/ml/datasets/banknote+authentication</a></p>
<section id="read-data">
<h3>Read data<a class="headerlink" href="#read-data" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># read data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data_banknote_authentication.txt&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;curtosis&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Banknotes&quot;</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variance</th>
      <th>skewness</th>
      <th>curtosis</th>
      <th>entropy</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
      <td>1372.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.433735</td>
      <td>1.922353</td>
      <td>1.397627</td>
      <td>-1.191657</td>
      <td>0.444606</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.842763</td>
      <td>5.869047</td>
      <td>4.310030</td>
      <td>2.101013</td>
      <td>0.497103</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-7.042100</td>
      <td>-13.773100</td>
      <td>-5.286100</td>
      <td>-8.548200</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-1.773000</td>
      <td>-1.708200</td>
      <td>-1.574975</td>
      <td>-2.413450</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.496180</td>
      <td>2.319650</td>
      <td>0.616630</td>
      <td>-0.586650</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.821475</td>
      <td>6.814625</td>
      <td>3.179250</td>
      <td>0.394810</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>6.824800</td>
      <td>12.951600</td>
      <td>17.927400</td>
      <td>2.449500</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="select-features-and-training-sets">
<h3>Select features and training sets<a class="headerlink" href="#select-features-and-training-sets" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create training and validation test sets</span>
<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">]</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;genuine&quot;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;counterfeit&quot;</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span>


<span class="n">plot_Xy</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot: xlabel=&#39;variance&#39;, ylabel=&#39;skewness&#39;&gt;
</pre></div>
</div>
<img alt="../../_images/svm-linear_8_1.png" src="../../_images/svm-linear_8_1.png" />
</div>
</div>
</section>
</section>
<section id="linear-support-vector-machines-svm">
<h2>Linear Support Vector Machines (SVM)<a class="headerlink" href="#linear-support-vector-machines-svm" title="Permalink to this heading">#</a></h2>
<p>A linear support vector machine (SVM) is a binary classifier that uses a linear expression to determine the classification.</p>
<div class="math notranslate nohighlight">
\[y = \text{sgn}\ ( w^\top x + b)\]</div>
<p>where <span class="math notranslate nohighlight">\(w\in \mathbb{R}^p\)</span> is a set of coefficients and <span class="math notranslate nohighlight">\(w^\top x\)</span> is the dot product. In effect, the linear function divides the feature space <span class="math notranslate nohighlight">\(\mathbb{R}^p\)</span> with a hyperplane specified by <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>A training or validation set consists of <span class="math notranslate nohighlight">\(n\)</span> observations <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> where <span class="math notranslate nohighlight">\(y_i = \pm 1\)</span> and <span class="math notranslate nohighlight">\(x_i\in\mathbb{R}^p\)</span> for <span class="math notranslate nohighlight">\(i=1, \dots, n\)</span>. The training task is to find coefficients <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span> and <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span> to achieve high precision and high recall for a validation set. All points <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> for <span class="math notranslate nohighlight">\(i\in 1, \dots, n\)</span> in a training or validation set are successfully classified if the</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
    y_i (w^\top x_i + b) &amp; &gt; 0 &amp; \forall i = 1, 2, \dots, n.
\end{align}
\]</div>
<p>For numerical reasons, however, it is convenient to add a margin and impose a slightly modified condition for correctly classified points, namely</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i (w^\top x_i + b) &amp; \geq 1 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\]</div>
<p>which defines a <strong>hard-margin</strong> classifier where the size of the margin is determined by the scale of <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>In practice, however, it is not always possible to find <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span> that separate all the data perfectly. The sample data displayed above for instance cannot be perfectly separated into two classes. Therefore, we need to minimize a measure of “things going wrong”. For that reason, when fitting SVMs to the data, it is common to use a <strong>soft-margin</strong> classifier. Given parameters <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>, the <strong>hinge-loss</strong> function is defined as</p>
<div class="math notranslate nohighlight">
\[
\ell(x, y) = \left(1 - y(w^\top x + b)\right)^+,
\]</div>
<p>using the notation <span class="math notranslate nohighlight">\(z^+ = \max(0, z)\)</span>.</p>
<p>The hinge-loss function has properties that make it useful fitting linear support vector machine. For a properly classified point the hinge-loss will be less than one but never smaller than zero. For a misclassified point, however, the hinge-loss function is greater than one and will grows in proportion to how far away the feature vector is from the separation plane. Minimizing the sum of hinge-loss functions locates an hyperplane that trades off between a margin for correctly classified points and minimizing the distance between the hyperplane and misclassified points.</p>
<p>The fitting problem is formulated as the problem of minimizing the hinge-loss function over all the data samples:</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
    \min_{w, b} \frac{1}{n}\sum_{i=1}^n \left(1 - y_i(w^\top x_i + b)\right)^+ .
\end{align*}
\]</div>
<p>However, the practice has shown that minimizing this term alone leads to classifiers with a potentially large magnitude of the entries of <span class="math notranslate nohighlight">\(w\)</span> and which potentially perform poorly on new data samples. For that reason, the concept of \emph{regularization} was invented that adds a term that penalizes the magnitude of <span class="math notranslate nohighlight">\(w\)</span>. In most formulations a norm <span class="math notranslate nohighlight">\(\|w\|\)</span> is used for regularization, commonly a sum of squares such as <span class="math notranslate nohighlight">\(\|w\|_2^2\)</span>. Another choice is <span class="math notranslate nohighlight">\(\|w\|_1\)</span> which, similarly to Lasso regression, may result in sparse weighting vector <span class="math notranslate nohighlight">\(w\)</span> indicating which elements of the feature vector can be neglected for classification purposes. These considerations result in the objective function</p>
<div class="math notranslate nohighlight">
\[
    \min_{w, b}\left[ \frac{1}{n}\sum_{i=1}^n \left(1 - y_i(w^\top x_i + b)\right)^+ + \lambda \|w\|_1\right]
\]</div>
<p>which by introducing <span class="math notranslate nohighlight">\(n\)</span> auxiliary nonnegative variables <span class="math notranslate nohighlight">\(z\)</span>’s can be solved by the following LP:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{z, w, b}\quad  &amp; \frac{1}{n}  \sum_{i=1}^n z_i + \lambda \|w\|_1 \\
\text{s.t.} \quad &amp;  z_i \geq 1 - y_i(w^\top x_i + b) &amp; \forall i = 1, \dots, n \\
&amp; z_i \geq 0 &amp; \forall i = 1, \dots, n.
\end{align*}
\end{split}\]</div>
<p>This is the primal optimization problem in decision variables <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span>, <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span>, and <span class="math notranslate nohighlight">\(z\in\mathbb{R}^n\)</span>, a total of <span class="math notranslate nohighlight">\(n + p + 1\)</span> unknowns with <span class="math notranslate nohighlight">\(2n\)</span> constraints.</p>
</section>
<section id="alternative-formulation-of-linear-svm">
<h2>Alternative Formulation of Linear SVM<a class="headerlink" href="#alternative-formulation-of-linear-svm" title="Permalink to this heading">#</a></h2>
<p>The standard formulation of a linear support vector machine uses training sets <span class="math notranslate nohighlight">\(p\)</span>-element feature vectors <span class="math notranslate nohighlight">\(x_i\in\mathbb{R}^p\)</span>, a classification for those vectors, <span class="math notranslate nohighlight">\(y_i = \pm 1\)</span> and a classifier defined by <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span> and <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span></p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y &amp; = \text{sgn}(w^\top x + b)
\end{align*}
\]</div>
<p>The parameter <span class="math notranslate nohighlight">\(b\)</span> is an annoying term that unnecessarily clutters the presentation and derivations. As an alternative formulation, consider an augmented feature vector <span class="math notranslate nohighlight">\(\bar{x} = (1, x) \in \mathbb{R}^{p+1}\)</span> and parameter vector <span class="math notranslate nohighlight">\(\bar{w} = (b, w) \in \mathbb{R}^{p+1}\)</span>. The linear SVM machine then becomes</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y &amp; = \text{sgn}(\bar{w}^\top \bar{x})
\end{align*}
\]</div>
<p>If a hard-margin classifier exists for a training or validation set <span class="math notranslate nohighlight">\((\bar{x}_i, y_i)\)</span> for <span class="math notranslate nohighlight">\(i=1, \dots, n\)</span> then it would satisfy</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i \bar{w}^\top \bar{x}_i &amp; \geq 1 &amp; \forall i \in 1, 2, \dots, n
\end{align*}
\]</div>
<p>The separating hyperplane consists of all points normal to <span class="math notranslate nohighlight">\(\bar{w}\)</span>. The distance between <span class="math notranslate nohighlight">\(x_i\)</span> and the separating  hyperplane is</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{w}^\top \bar{x}_i}{\|\bar{w}\|}\]</div>
<p>The soft-margin classifier is found by solving</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min \frac{1}{2} \|\bar{w}\|_2^2 &amp; + \frac{c}{n}\sum_{i=1}^n z_i \\
\text{s.t.} \qquad z_i &amp; \geq 1 - y_i \bar{w}^\top \bar{x}_i &amp; \forall i = 1, 2, \dots, n \\
z_i &amp; \geq 0 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\end{split}\]</div>
<p>Recasting as a conic program</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r + \frac{c}{n} 1^\top z\\
\text{s. t.}\qquad &amp; (r, 1, \bar{w}) \in Q_r^{3 + p} \\
&amp; z + F \bar{w} \geq 1  \\
&amp; z \geq 0 \\
\end{align*}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.kernel</span> <span class="k">as</span> <span class="nn">pmo</span>

<span class="k">def</span> <span class="nf">svm_conic_primal</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">())</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">primal</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">+</span> <span class="p">(</span><span class="n">c</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)))</span>

    <span class="n">m</span><span class="o">.</span><span class="n">qr</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">)),</span> <span class="n">lb</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">pmo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;mosek_direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">m</span>

<span class="n">c</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="o">%</span><span class="k">timeit</span> svm_conic_primal(X_train, y_train, c)
<span class="n">m</span> <span class="o">=</span> <span class="n">svm_conic_primal</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

<span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>

<span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
    
<span class="nb">print</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>257 ms ± 16.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
0.07011113915067575
0 0.03678891711068851
1 -0.35760476998562574
2 -0.10482214559845585

6 1.5820726062971888
8 1.5187471422802423
9 1.7717945764473657
14 1.572197142580981
16 1.3860547949920645
25 1.087752350878577
30 1.0947384589038558
46 1.1100515828416764
47 1.5808951348041997
54 1.2095914880291798
57 1.3965115394040573
68 1.873241458774625
72 1.1522112542291991
78 1.5474352479061102
94 1.7622950163577746
96 2.2961165669456425
97 1.5576803234952112
111 1.8553133703593936
116 1.0204531356121476
126 1.1930793591040918
132 1.4648433034946948
152 1.71183312979891
154 1.4294280814171314
155 1.633981774722139
176 1.1127390190050908
178 1.1937595749548195
180 1.1307148704684875
182 1.11811184086215
188 1.1957626710231517
194 1.021609565227067
207 1.5324749529623012
210 1.7896321401527064
211 1.3805425573472425
226 2.1891759676448714
244 1.5919009887779254
252 1.11607147239279
257 1.5643082047265884
259 1.570796726863365
263 1.2113592324667886
268 1.0024470781686379
292 1.3607499189292633
304 1.2048797068788175
307 1.5948967775822183
314 1.0299988914697784
343 1.0821206058443693
355 1.9954946041875448
381 1.3298019294200794
388 1.0464237960289822
390 1.2444292221275892
393 1.3860690621690648
413 1.0414905539921435
415 1.2480130715557844
428 1.5811120404506473
431 1.7356298720224546
445 1.8491153283098685
446 1.3743680644435226
455 1.1731294566138588
457 1.1358934376380254
467 1.8758822190243611
468 1.0101454411110098
481 1.6196841520307346
486 1.2674438527578857
498 1.2827172899700796
518 1.051255784464328
520 1.3423911480151016
521 2.0049171873602125
527 1.5299402940748075
528 1.1023439807974693
530 1.6734865923956779
539 1.6398453649503617
543 1.1930793591040918
545 1.6760061742642605
546 1.3707747625905262
548 1.6396228032425093
555 1.8222850443309586
557 1.4455400007047052
559 1.0307272397111014
569 1.916459594378694
582 1.0497076662611657
605 1.132457036423308
608 1.0101994033397228
624 1.1042146388769447
629 1.016812133058243
639 1.1101457166943016
648 1.2498747723000578
653 1.0640785457193473
661 1.5116540539876175
664 1.1851361270780367
671 1.3860690621690648
673 1.7837102725307494
698 1.8756653576289608
702 1.1930793591040918
710 1.8248416159200536
717 1.7361502143313707
719 1.1553397317029035
720 1.2927097392375417
725 1.4195704177243316
727 1.0764498132623508
728 1.1077881020904319
734 1.1950247813254717
747 1.041417427958914
756 2.10347951446582
766 1.0890013601677784
783 1.8113860808503137
811 1.0859351036838045
815 1.3860690621690648
818 1.030482197175682
820 1.6161027423647005
821 1.370271286589992
823 1.2193651249128286
832 1.2701139011622038
844 1.2838255541513985
857 1.2332888898244727
860 1.9974846515744262
864 1.9724288527409701
873 1.567789128943318
875 1.225514716587396
878 1.1755626509902422
882 1.5441443298866626
901 1.1930793591040918
910 1.3121405630351703
915 1.2220601310892707
919 1.7077813203856906
952 1.6108036575603981
957 1.763822826625848
960 1.3860690621690648
965 1.3103021646295916
976 1.43265063599315
978 1.0392338850660334
981 1.8598358416469178
988 1.5830650022663881
992 1.7154553993520096
993 1.0305994114132795
998 1.2652017576035979
1009 1.3915176011111177
1014 1.3285302308925369
1017 1.020146286684478
1035 1.378306718464854
1037 1.2692788252509584
1042 1.208910551567952
1055 1.4848561799008515
1073 1.1418121117289723
1094 1.63783146397018
</pre></div>
</div>
</div>
</div>
<p>Creating a differentiable Lagrangian with dual factors <span class="math notranslate nohighlight">\(\alpha_i\)</span> for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>, the task is to find saddle points of</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L} &amp; = \frac{1}{2} \|\bar{w}\|_2^2 + \frac{c}{n}\sum_{i=1}^n z_i + \sum_{i=1}^n \alpha_i (1 - y_i \bar{w}^\top \bar{x}_i - z_i) + \sum_{i=1}^n \beta_i (-z_i) \\
\end{align*}
\end{split}\]</div>
<p>Taking derivatives with respect to the primal variables</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial \mathcal{L}}{\partial z_i} &amp; = \frac{c}{n} - \alpha_i - \beta_i = 0 \implies 0 \leq \alpha_i \leq \frac{c}{n}\\
\frac{\partial \mathcal{L}}{\partial \bar{w}} &amp; = \bar{w}  - \sum_{i=1}^n \alpha_i y_i \bar{x}_i = 0 \implies  \bar{w} = \sum_{i=1}^n \alpha_i y_i \bar{x}_i \\
\end{align*}
\end{split}\]</div>
<p>resulting in the dual formulation</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\max_{\alpha_i}\ &amp;  \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( \bar{x}_i^\top \bar{x}_j ) \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>Rearranging as a standard quadratic program in <span class="math notranslate nohighlight">\(n\)</span> variables <span class="math notranslate nohighlight">\(\alpha_i\)</span> for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{\alpha_i}\ &amp; \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( \bar{x}_i^\top \bar{x}_j ) -  \sum_{i=1}^n \alpha_i \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>The <span class="math notranslate nohighlight">\(n \times n\)</span> <strong>Gram matrix</strong> is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}G = \begin{bmatrix} 
\bar{x}_1^\top \bar{x}_1 &amp; \dots &amp; \bar{x}_1^\top \bar{x}_n \\ 
\vdots &amp; \ddots &amp; \vdots \\ 
\bar{x}_n^\top \bar{x}_1 &amp; \dots &amp; \bar{x}_n^\top \bar{x}_n 
\end{bmatrix}\end{split}\]</div>
<p>where each entry is dot product of two vectors <span class="math notranslate nohighlight">\(\bar{x}_i, \bar{x}_j \in \mathbb{R}^{p+1}\)</span>.</p>
<p>Compared to the primal, the dual formulation has reduced to the number of decision variables from <span class="math notranslate nohighlight">\(n + p + 1\)</span> to <span class="math notranslate nohighlight">\(n\)</span>. But this has come with the significant penalty of introducing a dense matrix with <span class="math notranslate nohighlight">\(n^2\)</span> coefficients and potential processing time of order <span class="math notranslate nohighlight">\(n^3\)</span>. For large training sets, <span class="math notranslate nohighlight">\(n\sim 10^4-10^5\)</span> this is prohibitively expensive.</p>
<section id="reformulation-as-a-conic-program">
<h3>Reformulation as a conic program<a class="headerlink" href="#reformulation-as-a-conic-program" title="Permalink to this heading">#</a></h3>
<p>Introduce the <span class="math notranslate nohighlight">\(n \times (p+1)\)</span> matrix <span class="math notranslate nohighlight">\(F\)</span> defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}F = \begin{bmatrix} y_1 \bar{x}_1^\top \\ y_2 \bar{x}_2^\top \\ \vdots \\ y_n \bar{x}_n^\top \end{bmatrix}\end{split}\]</div>
<p>Then introducing an additional decision variabl <span class="math notranslate nohighlight">\(r \geq 0\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r - 1^\top \alpha\\
\text{s. t.}\qquad &amp; \alpha^\top F F^\top \alpha \leq 2 r \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>Using the notation <span class="math notranslate nohighlight">\(\mathcal{Q}^m_r\)</span> for a rotated quadratic cone (for example, see <a class="reference external" href="https://docs.mosek.com/modeling-cookbook/cqo.html#equation-eq-sec-qo-modeling-qset2">https://docs.mosek.com/modeling-cookbook/cqo.html#equation-eq-sec-qo-modeling-qset2</a>)</p>
<div class="math notranslate nohighlight">
\[\mathcal{Q}^m_r = \{z\in\mathbb{R}^m | 2z_1z_2 \geq z_3^2 + \cdots + z_m^2,\ z_1, z_2 \geq 0 \}\]</div>
<p>The quadratic constraint is reformulated as a rotated quadratic cone</p>
<div class="math notranslate nohighlight">
\[\frac{1}{2}\alpha^\top F F^\top \alpha \leq r \iff (r, 1, F^\top \alpha) \in Q_r^{3 + p}\]</div>
<p>The reformulated dual problem is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r - 1^\top \alpha\\
\text{s. t.}\qquad &amp; (r, 1, F^\top \alpha) \in Q_r^{3 + p} \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>The conic reformulation eliminates the need to store an <span class="math notranslate nohighlight">\(n\times n\)</span> Gram matrix.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \min_{r, \alpha}\ r - 1^\top \alpha\\
\text{s. t.}\qquad &amp; (r, 1, z) \in Q_r^{3 + p} \\
&amp; z = F^\top \alpha \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.kernel</span> <span class="k">as</span> <span class="nn">pmo</span>

<span class="k">def</span> <span class="nf">svm_conic_dual</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">c</span><span class="o">/</span><span class="n">n</span><span class="p">))</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">())</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1">#m.d[j] = pmo.linear_constraint(variables=[m.a, m.z[j]], coefficients=np.append(F[:,j], -1), rhs=0.0)</span>
        <span class="n">m</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">rhs</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
    <span class="n">m</span><span class="o">.</span><span class="n">o</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)))</span>
    <span class="n">m</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
    
    <span class="n">pmo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;mosek_direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">m</span>

<span class="n">c</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="o">%</span><span class="k">timeit</span> svm_conic_dual(X_train, y_train, c)
<span class="n">m</span> <span class="o">=</span> <span class="n">svm_conic_dual</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="o">&gt;</span> <span class="mf">1e-7</span> <span class="ow">and</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="o">&lt;</span> <span class="n">c</span><span class="o">/</span><span class="n">n</span> <span class="o">-</span> <span class="mf">1e-7</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>227 ms ± 13.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
0.07011113907200085
570 0.0005858380462467796
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="pyomo-implementation">
<h2>Pyomo Implementation<a class="headerlink" href="#pyomo-implementation" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>


<span class="k">def</span> <span class="nf">svm_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">()</span>

    <span class="c1"># zero-based indexing</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">m</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wpos</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wneg</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Constraint</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">hinge_loss</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span> <span class="o">+</span> <span class="n">lambd</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">m</span><span class="o">.</span><span class="n">wpos</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">wneg</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span>
        <span class="p">)</span>

    <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;glpk&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">()</span>

    <span class="c1"># return a binary classifier</span>
    <span class="k">def</span> <span class="nf">svm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">w</span> <span class="o">@</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

    <span class="n">svm</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">w</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>

    <span class="k">return</span> <span class="n">svm</span>


<span class="c1"># create a linear SVM binary classifier</span>

<span class="o">%</span><span class="k">timeit</span> svm = svm_fit(X_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>395 ms ± 23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">svm</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>

    <span class="n">true_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">false_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">false_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">true_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">tp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">true_pos</span><span class="p">)</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">false_pos</span><span class="p">)</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">false_neg</span><span class="p">)</span>
    <span class="n">tn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">true_neg</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;                   Test Data (n = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;                  y = 1       y = -1&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Predict y =  1    </span><span class="si">{</span><span class="n">tp</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">      </span><span class="si">{</span><span class="n">fp</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">    precision = </span><span class="si">{</span><span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Predict y = -1    </span><span class="si">{</span><span class="n">fn</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">      </span><span class="si">{</span><span class="n">tn</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2"> &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;      Recall =     </span><span class="si">{</span><span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">plot</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">w</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">b</span>
        <span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()</span>
        <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="p">[</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">xmin</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">xmax</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">5.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">true_pos</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">true_pos</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">true_neg</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">true_neg</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;true positive&quot;</span><span class="p">,</span> <span class="s2">&quot;true negative&quot;</span><span class="p">])</span>

    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">false_pos</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">false_pos</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plot_Xy</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">false_neg</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">false_neg</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">svm_line</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;false negative&quot;</span><span class="p">,</span> <span class="s2">&quot;false_positive&quot;</span><span class="p">])</span>


<span class="n">svm</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                   Test Data (n = 275)
                  y = 1       y = -1
 Predict y =  1      96        21    precision = 0.821
 Predict y = -1      13       145 
      Recall =     0.881
</pre></div>
</div>
<img alt="../../_images/svm-linear_17_1.png" src="../../_images/svm-linear_17_1.png" />
<img alt="../../_images/svm-linear_17_2.png" src="../../_images/svm-linear_17_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_train_full</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_train_full</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_test_full</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_test_full</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># fit svm and test</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">)</span>
<span class="n">svm_test</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_test_full</span><span class="p">,</span> <span class="n">y_test_full</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                   Test Data (n = 275)
                  y = 1       y = -1
 Predict y =  1     109         0    precision = 1.000
 Predict y = -1       0       166 
      Recall =     1.000
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-svm-dual">
<h2>The SVM Dual<a class="headerlink" href="#the-svm-dual" title="Permalink to this heading">#</a></h2>
<p>Creating the dual of the support vector machine will turn out to have practical consequences. Creating the dual requires a differentiable objective function. For this reason, the regularization term is changed to the 2-norm of <span class="math notranslate nohighlight">\(w\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{z, w, b}\  \frac{1}{2} \|w\|_2^2 + \frac{c}{n}  \sum_{i=1}^n z_i \\
\\
\text{s.t.}\qquad 1 - y_i(w^\top x_i + b) - z_i &amp; \leq 0 &amp; \forall i = 1, \dots, n \\
- z_i &amp; \leq 0 &amp; \forall i = 1, \dots, n
\end{align*}
\end{split}\]</div>
<p>where the regularization parameter shifted to <span class="math notranslate nohighlight">\(c\)</span>, and the constraints restated in standard form. This is a quadratic problem in <span class="math notranslate nohighlight">\(n + p + 1\)</span> variables and <span class="math notranslate nohighlight">\(2n\)</span> constraints.</p>
<p>The Lagrangian <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L} &amp; = \frac{1}{2} \|w\|_2^2 + \frac{c}{n}\sum_{i=1}^n z_i + \sum_{i=1}^n \alpha_i (1 - y_i(w^\top x_i + b) - z_i) + \sum_{i=1}^n \beta_i (-z_i) \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(2n\)</span> non-negative Lagrange multipliers <span class="math notranslate nohighlight">\(\alpha_i \geq 0\)</span> and <span class="math notranslate nohighlight">\(\beta_1 \geq 0\)</span> have been introduced for <span class="math notranslate nohighlight">\(i \in 1,\dots,n\)</span>. Intuitively, the Lagrange variables are penalty weights assigned to the inequality constraints introduced into a modified objective function. If the penalties are large enough then the constraints will be satisfied.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial \mathcal{L}}{\partial z_i} &amp; = \frac{c}{n} - \alpha_i - \beta_i = 0 \implies 0 \leq \alpha_i \leq \frac{c}{n}\\
\frac{\partial \mathcal{L}}{\partial w} &amp; = w  - \sum_{i=1}^n \alpha_i y_i x_i = 0 \implies  w = \sum_{i=1}^n \alpha_i y_i x_i \\
\frac{\partial \mathcal{L}}{\partial b} &amp; = -\sum_{i=1}^n \alpha_i y_i = 0 \implies \sum_{i=1}^n \alpha_i y_i = 0 \\
\end{align*}
\end{split}\]</div>
<p>The dual problem is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\max_{\alpha_i}\ &amp;  \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( x_i^\top x_j ) \\
\text{s. t.}\quad &amp; \sum_{i=1}^n \alpha_i y_i = 0 \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>Like the primal, the dual is a quadratic program. The dual, however, has only <span class="math notranslate nohighlight">\(n\)</span> decision variables compared to <span class="math notranslate nohighlight">\(n + p + 1\)</span> decision variables for the primal, and <span class="math notranslate nohighlight">\(n + 1\)</span> constraints compared to <span class="math notranslate nohighlight">\(2n\)</span> constraints for the primal. This reduction is significant for problems with many features (i.e, large <span class="math notranslate nohighlight">\(p\)</span>), or for large training sets (i.e., large <span class="math notranslate nohighlight">\(n\)</span>). The case of large <span class="math notranslate nohighlight">\(p\)</span> becomes important when extending SVM to nonlinear classification using kernels.</p>
<p>Note, however, that the reduced number of decision variables and constraints in the dual problem requires computing <span class="math notranslate nohighlight">\(\frac{n(n+1)}{2}\)</span> inner products <span class="math notranslate nohighlight">\((x_i^\top x_j)\)</span> for <span class="math notranslate nohighlight">\(i \leq j\)</span> and <span class="math notranslate nohighlight">\(i,j\in \mathbb{R}^n\)</span>.   The inner products can be arranged as a symmetric matrix
$<span class="math notranslate nohighlight">\(
\begin{align*}
K = [k_{i,j}] = X X^\top = \begin{bmatrix}
x_1^\top x_1 &amp; x_1^\top x_2 &amp; \dots &amp; x_1^\top x_n \\
x_2^\top x_1 &amp; x_2^\top x_2 &amp; \dots &amp; x_2^\top x_n \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_n^\top x_1 &amp; x_n^\top x_2 &amp; \dots &amp;  x_n^\top x_n \\
\end{bmatrix}
\end{align*}
\)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n\times p}\)</span> is the matrix formed by the <span class="math notranslate nohighlight">\(n\)</span> feature vectors <span class="math notranslate nohighlight">\(x_i\)</span> for <span class="math notranslate nohighlight">\(i=1, 2, \dots, n\)</span>. The symmetry of <span class="math notranslate nohighlight">\(K\)</span>, which is known as the Gram matrix (or Grammian) is a consequence of the symmetry of the inner product for real number spaces.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
w^* &amp; = \sum_{i=1}^n \alpha_i^* y_i x_i \\
b^* &amp; = y_k - (w^*)^\top x_k &amp; \text{for any }k\ni 0 &lt; \alpha_k &lt; \frac{c}{n} \\
\end{align*}
\end{split}\]</div>
<p>which can be written entirely in terms of the inner product.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
w^* &amp; = \sum_{i=1}^n \alpha_i^* y_i x_i \\
b^* &amp; = y_k - \sum_{i=1}^n \alpha_i^* y_i x_i^\top x_k &amp; \text{for any }k\ni 0 &lt; \alpha_k &lt; \frac{c}{n} 
\end{align*}
\end{split}\]</div>
<p>Given a value for the feature vector <span class="math notranslate nohighlight">\(x\in\mathbb{R}^p\)</span>, the classifier <span class="math notranslate nohighlight">\(\hat{y} = \text{sgn}\ \left((w^*)^\top x + b^* \right)\)</span> is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\hat{y} &amp; = \text{sgn}\ \left( y_k + \sum_{i=1}^n \alpha_i^* y_i x^\top_i (x - x_k) \right)\\
\end{align*}
\end{split}\]</div>
<p>This is result has important consequences. The key point is that is that the dual optimization problem can be solved with knowledge of the inner products appearing in the Gram matrix <span class="math notranslate nohighlight">\(K\)</span>, and the resulting classifier needs only inner products of training set data with the difference <span class="math notranslate nohighlight">\(x - x_k\)</span> for some <span class="math notranslate nohighlight">\(k\)</span> found in the optimization calculation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>


<span class="k">def</span> <span class="nf">svm_dual_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">()</span>

    <span class="n">X_np</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

    <span class="n">K</span> <span class="o">=</span> <span class="n">X_np</span> <span class="o">@</span> <span class="n">X_np</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># zero-based indexing</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Constraint</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">sumya</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="nd">@m</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">maximize</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span>
        <span class="p">)</span>

    <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">svm</span><span class="p">():</span>
        <span class="k">pass</span>

    <span class="k">return</span> <span class="n">svm</span>


<span class="c1"># create a linear SVM binary classifier</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">m</span> <span class="o">=</span> <span class="n">svm_dual_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s2">&quot;mosek_direct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

<span class="nn">File ~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pyomo/solvers/plugins/solvers/direct_solver.py:120,</span> in <span class="ni">DirectSolver.solve</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span> 
<span class="g g-Whitespace">    </span><span class="mi">117</span>     <span class="c1"># we&#39;re good to go.</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span>     <span class="n">initial_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">120</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_presolve</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">122</span>     <span class="n">presolve_completion_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">123</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_timing</span><span class="p">:</span>

<span class="nn">File ~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pyomo/solvers/plugins/solvers/direct_solver.py:63,</span> in <span class="ni">DirectSolver._presolve</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span>     <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;The </span><span class="si">{0}</span><span class="s2"> plugin method &#39;_presolve&#39; must be supplied a single problem instance - </span><span class="si">{1}</span><span class="s2"> were &quot;</span> <span class="o">+</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span>            <span class="s2">&quot;supplied.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">63</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_instance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span> <span class="n">DirectOrPersistentSolver</span><span class="o">.</span><span class="n">_presolve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>

<span class="nn">File ~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pyomo/solvers/plugins/solvers/mosek_direct.py:180,</span> in <span class="ni">MOSEKDirect._set_instance</span><span class="nt">(self, model, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">178</span> <span class="k">def</span> <span class="nf">_set_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="o">=</span><span class="p">{}):</span>
<span class="g g-Whitespace">    </span><span class="mi">179</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_range_constraints</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">180</span>     <span class="nb">super</span><span class="p">(</span><span class="n">MOSEKDirect</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_set_instance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">181</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_pyomo_cone_to_solver_cone_map</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">182</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_solver_cone_to_pyomo_cone_map</span> <span class="o">=</span> <span class="n">ComponentMap</span><span class="p">()</span>

<span class="nn">File ~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pyomo/solvers/plugins/solvers/direct_or_persistent_solver.py:176,</span> in <span class="ni">DirectOrPersistentSolver._set_instance</span><span class="nt">(self, model, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">173</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">IBlock</span><span class="p">,</span> <span class="n">Block</span><span class="p">,</span> <span class="n">_BlockData</span><span class="p">)):</span>
<span class="g g-Whitespace">    </span><span class="mi">174</span>     <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;The problem instance supplied to the </span><span class="si">{0}</span><span class="s2"> plugin &quot;</span> \
<span class="g g-Whitespace">    </span><span class="mi">175</span>           <span class="s2">&quot;&#39;_presolve&#39; method must be a Model or a Block&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<span class="ne">--&gt; </span><span class="mi">176</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pyomo_model</span> <span class="o">=</span> <span class="n">model</span>
<span class="g g-Whitespace">    </span><span class="mi">178</span> <span class="bp">self</span><span class="o">.</span><span class="n">_symbolic_solver_labels</span> <span class="o">=</span> <span class="n">kwds</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;symbolic_solver_labels&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_symbolic_solver_labels</span><span class="p">)</span>

<span class="ne">ValueError</span>: The problem instance supplied to the &lt;class &#39;pyomo.solvers.plugins.solvers.mosek_direct.MOSEKDirect&#39;&gt; plugin &#39;_presolve&#39; method must be a Model or a Block
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/05"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="markowitz_portfolio_with_chance_constraint.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Portfolio optimization with chance constraint</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="refinery-production.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Extra material: Refinery production and shadow pricing</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The MO Book Group<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>