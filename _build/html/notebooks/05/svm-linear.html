
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>A Linear Support Vector Machine Classifier &#8212; Companion Notebooks for Data-Driven Mathematical Optimization in Python</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6. Conic Optimization" href="../06/06.00.html" />
    <link rel="prev" title="Minimum Risk-Free Rate of Return" href="farkas-lemma.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-DVQ7NZ8CYZ"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-DVQ7NZ8CYZ');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo-02.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Companion Notebooks for Data-Driven Mathematical Optimization in Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Data-Driven Mathematical Optimization in Python
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/01.00.html">
   1. Mathematical Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/alice-rose.html">
     Alice’s Rose
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/Pop-Up-Shop.html">
     Scenario Analysis: Pop Up Shop
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/02.00.html">
   2. Linear Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/lad-regression.html">
     Least Absolute Deviation (LAD) Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/lad-regression-wine-quality.html">
     Predicting Wine Quality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/making-the-best-of-the-worst.html">
     Making the Best of the Worst
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/mad-portfolio-optimization.html">
     MAD Portfolio Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/fractional-bim.html">
     Fractional BIM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/large-example-chapter-2.html">
     Caroline’s raw material planning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03/03.00.html">
   3. Mixed Integer Linear Programming
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/cryptarithms.html">
     Cryptarithms: Send More Money
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/strip-packing.html">
     Strip Packing: Placing Boxes on a Shelf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/simple-production-model-gdp.html">
     Production Model with Disjuncts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/recharging-electric-vehicle.html">
     Recharging Strategy for an Electric Vehicle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/Shift-Scheduling.html">
     Shift Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/machine-scheduling.html">
     Machine Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/job-shop-scheduling.html">
     Job Shop Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/maintenance-planning.html">
     Maintenance Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/large-example-chapter-3.html">
     BIM Production
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04/04.00.html">
   4. Network Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/dina-tables-and-variations.html">
     Dina’s table seating arrangements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/Transportation.html">
     Transportation and Allocation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/forex-arbitrage.html">
     Forex Arbitrage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/cryptocurrency-arbitrage.html">
     Crypto Currency Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/shortest-path-road-networks.html">
     Computing a real life shortest path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/complete-example-ch4-power-network.html">
     Energy dispatch problem
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="05.00.html">
   5. Convex Optimization
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="milk-pooling.html">
     Pooling and Blending
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bilinear-relaxations.html">
     McCormick Envelopes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="refinery-production.html">
     Refinery Production and Shadow Pricing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="detecting-change.html">
     Detecting Change
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="farkas-lemma.html">
     Minimum Risk-Free Rate of Return
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     A Linear Support Vector Machine Classifier
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/06.00.html">
   6. Conic Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/economic-order-quantity.html">
     Economic Order Quantity
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../07/07.00.html">
   7. Accounting for Uncertainty: Optimization Meets Reality
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08/08.00.html">
   8. Robust Optimization - Single Stage Problems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/ef-robust-optimization.html">
     Companion notebook to EF’s training on optimization with data uncertainty
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09/09.00.html">
   9. Stochastic Optimization - Single Stage Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10/10.00.html">
   10. Robust Optimization - Two Stage Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../11/11.00.html">
   11. Stochastic Optimization - Two Stage Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyomo_style_guide.html">
   Pyomo Style Guide
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notebooks/05/svm-linear.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/jckantor/MO-book/main?urlpath=tree/notebooks/05/svm-linear.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/jckantor/MO-book/blob/main/notebooks/05/svm-linear.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binary-classification">
   Binary Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-support-vector-machines-svm">
   Linear Support Vector Machines (SVM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-svm-dual">
   The SVM Dual
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-set">
   Data Set
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dimensionality-reduction-with-pca">
   Dimensionality Reduction with PCA
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-pca">
     Linear PCA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel-pca">
     Kernel PCA
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-svm-to-the-features">
   Fit SVM to the features
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-svm-classifier">
     Test SVM classifier
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#full-featured-svm">
   Full featured SVM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyomo-implementation">
   Pyomo Implementation
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>A Linear Support Vector Machine Classifier</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binary-classification">
   Binary Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-support-vector-machines-svm">
   Linear Support Vector Machines (SVM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-svm-dual">
   The SVM Dual
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-set">
   Data Set
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dimensionality-reduction-with-pca">
   Dimensionality Reduction with PCA
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-pca">
     Linear PCA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel-pca">
     Kernel PCA
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-svm-to-the-features">
   Fit SVM to the features
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-svm-classifier">
     Test SVM classifier
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#full-featured-svm">
   Full featured SVM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyomo-implementation">
   Pyomo Implementation
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="a-linear-support-vector-machine-classifier">
<h1>A Linear Support Vector Machine Classifier<a class="headerlink" href="#a-linear-support-vector-machine-classifier" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cvxpy</span> <span class="k">as</span> <span class="nn">cp</span>
</pre></div>
</div>
</div>
</div>
<section id="binary-classification">
<h2>Binary Classification<a class="headerlink" href="#binary-classification" title="Permalink to this headline">¶</a></h2>
<p>A binary classifier is a function for predicting a binary outcome <span class="math notranslate nohighlight">\(y = \pm 1\)</span> based the values of <span class="math notranslate nohighlight">\(p\)</span> features contained in a vector <span class="math notranslate nohighlight">\(x\in \mathbb{R}^p\)</span>.  A successful binary classifier will predict <span class="math notranslate nohighlight">\(y\)</span> with high precision and high recall.</p>
<ul class="simple">
<li><p><strong>Precision</strong>. The number of real positives divided by the number of predicted positives. High precision implies a low false positive rate.</p></li>
<li><p><strong>Recall</strong>. The number of real positives divided by number of actual positives. High recall test implies a low false negative rate.</p></li>
</ul>
<p>Consider, for example, an device that rejects counterfeit banknotes for a vending machine. A false positive would mean the vending machine would rejects a genuine banknote which would be frustrating to a user. Users of the vending machine, therefore, would prefer a device with high precision.</p>
<p>On the other hand, a false negative would mean the vending machine would accept a counterfeit banknote. The owner of the vending machine, therefore, would prefer a device with high reccall.</p>
<p>false positive  a counterfeit banknote, clearly an undesirable outcome for the seller. The seller would be interested in high precision. A buyer, however, may be frustrated if a valid banknote is needlessly rejected by the vending machine. The buyer would be interested in high recall.</p>
<p>The challenge of developing binary classifiers is to find features, and functions to evaluate those features, that provide the precision and recall needed for a particular application.</p>
</section>
<section id="linear-support-vector-machines-svm">
<h2>Linear Support Vector Machines (SVM)<a class="headerlink" href="#linear-support-vector-machines-svm" title="Permalink to this headline">¶</a></h2>
<p>Notes:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/">http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/</a></p></li>
</ul>
<p>A linear support vector machine is a binary classifier that uses linear form to determine the classification.</p>
<div class="math notranslate nohighlight">
\[y = \text{sgn}\ ( w^\top x + b)\]</div>
<p>where <span class="math notranslate nohighlight">\(w\in \mathbb{R}^p\)</span> is a set of coefficients and <span class="math notranslate nohighlight">\(w^\top x\)</span> is the dot product. In effect, the linear function divides the feature space <span class="math notranslate nohighlight">\(\mathbb{R}^p\)</span> with a hyperplane specified by <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>Given a training set consists of <span class="math notranslate nohighlight">\(n\)</span> observations <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> where <span class="math notranslate nohighlight">\(y_i = \pm 1\)</span> and <span class="math notranslate nohighlight">\(x_i\in\mathbb{R}^p\)</span> for <span class="math notranslate nohighlight">\(i=1, \dots, n\)</span>, the computational task is to find coefficients <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span> and <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span> to achieve high precision and high recall for a validation set.</p>
<p>A point  <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> in the validation set is successfully classified if the value</p>
<div class="math notranslate nohighlight">
\[ y_i (w^\top x_i + b) &gt; 0 \]</div>
<p>whereas the point is mis-classified if</p>
<div class="math notranslate nohighlight">
\[ y_i (w^\top x_i + b) &lt; 0 \]</div>
<p>Given parameters <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>, the <strong>hinge-loss</strong> function is defined as</p>
<div class="math notranslate nohighlight">
\[\ell(x, y) = \left(1 - y(w^\top x + b)\right)_+\]</div>
<p>using the notation <span class="math notranslate nohighlight">\(\left(z\right)_+ = \max(0, z)\)</span>. This loss function has several properties that make it useful fitting linear support vector machine.  For a mis-classified point, the hinge-loss function grows in proportion to the magnitude of</p>
<div class="math notranslate nohighlight">
\[1 - y_i\left(w^\top x_i + b\right)\]</div>
<p>which we call the <em>scoring</em> function. The scoring function assigns a large loss to data far away from the separation plane.  For correctly classified points the scoring function is reduced to a value no smaller than zero. A soft penalty is assigned to points that correctly classified but still near the separating hyperplane.</p>
<p>One approach to fitting a linear SVM is to assign a regularization term for <span class="math notranslate nohighlight">\(w\)</span>. In most formulations a norm <span class="math notranslate nohighlight">\(\|w\|\)</span> is used for regularization, commonly a sum of squares such as <span class="math notranslate nohighlight">\(\|w\|_2^2\)</span>. Another choice is <span class="math notranslate nohighlight">\(\|w\|_1\)</span> which, similar to Lasso regression, may result in sparse weighting vectors <span class="math notranslate nohighlight">\(w\)</span> indicating which elements of the feature vector can be neglected for classification purpose. These considerations result i the objective function</p>
<div class="math notranslate nohighlight">
\[\min_{w, b}\left[ \frac{1}{n}\sum_{i=1}^n \left(1 - y_i(w^\top x_i + b)\right)_+ + \lambda \|w\|_1\right]\]</div>
<p>which can be solved by linear programming.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{z, w, b}\ &amp; \frac{1}{n}  \sum_{i=1}^n z_i + \lambda \|w\|_1 \\
\text{s.t.}\qquad z_i &amp; \geq 1 - y_i(w^\top x_i + b) &amp; \forall i = 1, \dots, n \\
z_i &amp; \geq 0 &amp; \forall i = 1, \dots, n
\end{align*}
\end{split}\]</div>
<p>This is the primal optimization problem in decision variables <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span>, <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span>, and <span class="math notranslate nohighlight">\(z\in\mathbb{R}^n\)</span>, a total of <span class="math notranslate nohighlight">\(n + p + 1\)</span> unknowns with <span class="math notranslate nohighlight">\(2n\)</span> constraints.</p>
</section>
<section id="the-svm-dual">
<h2>The SVM Dual<a class="headerlink" href="#the-svm-dual" title="Permalink to this headline">¶</a></h2>
<p>Creating the dual of the support vector machine will turn out to have practical consequences. Creating the dual requires a differentiable objective function. For this reason, the regularization term is changed to the 2-norm of <span class="math notranslate nohighlight">\(w\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{z, w, b}\  \frac{1}{2} \|w\|_2^2 + \frac{c}{n}  \sum_{i=1}^n z_i \\
\\
\text{s.t.}\qquad 1 - y_i(w^\top x_i + b) - z_i &amp; \leq 0 &amp; \forall i = 1, \dots, n \\
- z_i &amp; \leq 0 &amp; \forall i = 1, \dots, n
\end{align*}
\end{split}\]</div>
<p>where the regularization parameter shifted to <span class="math notranslate nohighlight">\(c\)</span>, and the constraints restated in standard form. This is a quadratic problem in <span class="math notranslate nohighlight">\(n + p + 1\)</span> variables and <span class="math notranslate nohighlight">\(2n\)</span> constraints.</p>
<p>The Lagrangian <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L} &amp; = \frac{1}{2} \|w\|_2^2 + \frac{c}{n}\sum_{i=1}^n z_i + \sum_{i=1}^n \alpha_i (1 - y_i(w^\top x_i + b) - z_i) + \sum_{i=1}^n \beta_i (-z_i) \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(2n\)</span> non-negative Lagrange multipliers <span class="math notranslate nohighlight">\(\alpha_i \geq 0\)</span> and <span class="math notranslate nohighlight">\(\beta_1 \geq 0\)</span> have been introduced for <span class="math notranslate nohighlight">\(i \in 1,\dots,n\)</span>. Intuitively, the Lagrange variables are penalty weights assigned to the inequality constraints introduced into a modified objective function. If the penalties are large enough then the constraints will be satisfied.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial \mathcal{L}}{\partial z_i} &amp; = \frac{c}{n} - \alpha_i - \beta_i = 0 \implies 0 \leq \alpha_i \leq \frac{c}{n}\\
\frac{\partial \mathcal{L}}{\partial w} &amp; = w  - \sum_{i=1}^n \alpha_i y_i x_i = 0 \implies  w = \sum_{i=1}^n \alpha_i y_i x_i \\
\frac{\partial \mathcal{L}}{\partial b} &amp; = -\sum_{i=1}^n \alpha_i y_i = 0 \implies \sum_{i=1}^n \alpha_i y_i = 0 \\
\end{align*}
\end{split}\]</div>
<p>The dual problem is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\max_{\alpha_i}\ &amp;  \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( x_i^\top x_j ) \\
\text{s. t.}\quad &amp; \sum_{i=1}^n \alpha_i y_i = 0 \\
&amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>which is a quadratic program like the primal, but with <span class="math notranslate nohighlight">\(n\)</span> decision variables <span class="math notranslate nohighlight">\(\alpha_i\)</span> and <span class="math notranslate nohighlight">\(n + 1\)</span> constraints. The dual has <span class="math notranslate nohighlight">\(p+1\)</span> fewer decision variables and <span class="math notranslate nohighlight">\(n\)</span> fewer constraints than the primal. Give a solution <span class="math notranslate nohighlight">\(\alpha_i^*\)</span>, the</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
w^* &amp; = \sum_{i=1}^n \alpha_i^* y_i x_i \\
b^* &amp; = y_k - (w^*)^\top x_k &amp; \text{for any }k\ni 0 &lt; \alpha_k &lt; \frac{c}{n} \\
\end{align*}
\end{split}\]</div>
<p>This is a remarkable result.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
w^* &amp; = \sum_{i=1}^n \alpha_i^* y_i x_i \\
b^* &amp; = y_k - \sum_{i=1}^N \alpha_i^* y_i x_i^\top x_k &amp; \text{for any }k\ni 0 &lt; \alpha_k &lt; \frac{c}{n} 
\end{align*}
\end{split}\]</div>
<p>The classifier is then</p>
</section>
<section id="data-set">
<h2>Data Set<a class="headerlink" href="#data-set" title="Permalink to this headline">¶</a></h2>
<p>The following data set contains data from a collection genuine and counterfeit banknote specimens. The data includes four continuous statistical measures obtained from the wavelet transform of banknote images and a binary variable where 0 indicates genuine and 1 indicates counterfeit.</p>
<p><a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/banknote+authentication">https://archive.ics.uci.edu/ml/datasets/banknote+authentication</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">KernelPCA</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cvxpy</span> <span class="k">as</span> <span class="nn">cp</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data_banknote_authentication.txt&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;curtosis&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># create training and validation test sets</span>
<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">df_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;curtosis&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">]]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="n">df_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;curtosis&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="n">center</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">scale</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="c1"># center and scale with training d</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dimensionality-reduction-with-pca">
<h2>Dimensionality Reduction with PCA<a class="headerlink" href="#dimensionality-reduction-with-pca" title="Permalink to this headline">¶</a></h2>
<p>To provide an effective visualization, for a first attempt an SVM classifer we  will reduce the four observed features to the two dominant components returned by <a class="reference external" href="https://scikit-learn.org/stable/modules/decomposition.html#pca">principal component analysis</a> (PCA).</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html</a></p></li>
</ul>
<section id="linear-pca">
<h3>Linear PCA<a class="headerlink" href="#linear-pca" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># format PCA loadings and varianace ratios</span>
<span class="n">loadings</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;PC</span><span class="si">{</span><span class="n">_</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">)])</span>
<span class="n">loadings</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loadings</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s2">&quot;PC0&quot;</span><span class="p">,</span> <span class="s2">&quot;PC1&quot;</span><span class="p">,</span> <span class="s2">&quot;PC2&quot;</span><span class="p">,</span> <span class="s2">&quot;PC3&quot;</span><span class="p">],</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     variance  skewness  curtosis   entropy
PC0 -0.229949 -0.639035  0.610101  0.408086
PC1 -0.768108  0.033997  0.160167 -0.619032
PC2  0.591545 -0.094823  0.526893 -0.602882
PC3 -0.084899  0.762553  0.569655  0.294615
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;BarContainer object of 4 artists&gt;
</pre></div>
</div>
<img alt="../../_images/svm-linear_12_2.png" src="../../_images/svm-linear_12_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;PC0&quot;</span><span class="p">,</span> <span class="s2">&quot;PC1&quot;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">Xy_plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;genuine&quot;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;counterfeit&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span>

<span class="n">Xy_plot</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:xlabel=&#39;PC0&#39;, ylabel=&#39;PC1&#39;&gt;
</pre></div>
</div>
<img alt="../../_images/svm-linear_13_1.png" src="../../_images/svm-linear_13_1.png" />
</div>
</div>
</section>
<section id="kernel-pca">
<h3>Kernel PCA<a class="headerlink" href="#kernel-pca" title="Permalink to this headline">¶</a></h3>
<p>The first two principal components of linear PCA provides some, but not complete, discrimination between the two classes of banknotes. This motivates a look at kernel PCA. Kernel PCA embeds the feature space <span class="math notranslate nohighlight">\(x\in\mathbb{R}^p\)</span> in a higher dimensional space. Essential to the technique is to perform the embedding in such a way that the inner product in the higher dimensional space can be computed using a ‘kernel’ function in <span class="math notranslate nohighlight">\(\mathbb{R}^p\)</span>. (This is known as the ‘kernel trick’, also known as Mercer’s theorem.)</p>
<p>After several trials with different kernels and settings, a radial basis function kernel appears to separate the two classes of banknotes using two components.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">kpca_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="p">):</span>
    <span class="n">kpca</span> <span class="o">=</span> <span class="n">KernelPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">X_kpca</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">kpca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="n">X_kpca</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;KPC0&quot;</span><span class="p">,</span> <span class="s2">&quot;KPC1&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">X_kpca</span>
    
<span class="n">Xy_plot</span><span class="p">(</span><span class="n">kpca_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">Xy_plot</span><span class="p">(</span><span class="n">kpca_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:xlabel=&#39;KPC0&#39;, ylabel=&#39;KPC1&#39;&gt;
</pre></div>
</div>
<img alt="../../_images/svm-linear_15_1.png" src="../../_images/svm-linear_15_1.png" />
<img alt="../../_images/svm-linear_15_2.png" src="../../_images/svm-linear_15_2.png" />
</div>
</div>
</section>
</section>
<section id="fit-svm-to-the-features">
<h2>Fit SVM to the features<a class="headerlink" href="#fit-svm-to-the-features" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">svm_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">()</span>
    <span class="n">hinge_loss</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">pos</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span><span class="p">)))</span>
    <span class="n">problem</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="n">hinge_loss</span><span class="o">/</span><span class="n">n</span> <span class="o">+</span> <span class="n">alpha</span><span class="o">*</span><span class="n">cp</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">problem</span><span class="o">.</span><span class="n">solve</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">w</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">value</span>

<span class="k">def</span> <span class="nf">svm_plot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()</span>
    <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">xmin</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">xmax</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>

<span class="c1"># train svm on kpca of X_train</span>
<span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">kpca_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># plot kpca of X_train and svm</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">Xy_plot</span><span class="p">(</span><span class="n">kpca_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svm_plot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/svm-linear_17_0.png" src="../../_images/svm-linear_17_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># train</span>
<span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">kpca_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># compare to test data</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">Xy_plot</span><span class="p">(</span><span class="n">kpca_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">svm_plot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/svm-linear_18_0.png" src="../../_images/svm-linear_18_0.png" />
</div>
</div>
<section id="test-svm-classifier">
<h3>Test SVM classifier<a class="headerlink" href="#test-svm-classifier" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">svm_pred</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># train svm</span>
<span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">kpca_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_pred</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">kpca_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">compare</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">tn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_test</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_test</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_test</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; true positives = </span><span class="si">{</span><span class="n">tp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;false positives = </span><span class="si">{</span><span class="n">fp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; true negatives = </span><span class="si">{</span><span class="n">tn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;false negatives = </span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> 
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;      precision = </span><span class="si">{</span><span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;         recall = </span><span class="si">{</span><span class="n">tp</span><span class="o">/</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    

<span class="n">compare</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> true positives = 84
false positives = 7
 true negatives = 143
false negatives = 41
      precision = 0.923
         recall = 0.672
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="full-featured-svm">
<h2>Full featured SVM<a class="headerlink" href="#full-featured-svm" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># train</span>
<span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">svm_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># compare to test data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_pred</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>

<span class="n">compare</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> true positives = 124
false positives = 2
 true negatives = 148
false negatives = 1
      precision = 0.984
         recall = 0.992
</pre></div>
</div>
</div>
</div>
</section>
<section id="pyomo-implementation">
<h2>Pyomo Implementation<a class="headerlink" href="#pyomo-implementation" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyomo.environ</span> <span class="k">as</span> <span class="nn">pyo</span>

<span class="k">def</span> <span class="nf">pyomo_svm_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">ConcreteModel</span><span class="p">()</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">RangeSet</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">m</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wpos</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">wneg</span> <span class="o">=</span> <span class="n">pyo</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">NonNegativeReals</span><span class="p">)</span>
    
    <span class="nd">@m</span><span class="o">.</span><span class="n">Constraint</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">hinge_loss</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
    
    <span class="nd">@m</span><span class="o">.</span><span class="n">Objective</span><span class="p">(</span><span class="n">sense</span><span class="o">=</span><span class="n">pyo</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">n</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">wpos</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">wneg</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    
    <span class="n">pyo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;glpk&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">p</span><span class="p">]()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span>
    
<span class="n">pyomo_svm_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([-10.3785571 , -11.83047461, -10.61068032,  -0.57274353]),
 -5.10017690921349)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">svm_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pyomo_svm_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([[-10.3785571 ],
       [-11.83047461],
       [-10.61068032],
       [ -0.57274353]]), array(-5.10017691))
(array([-10.3785571 , -11.83047461, -10.61068032,  -0.57274353]), -5.10017690921349)
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/05"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="farkas-lemma.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Minimum Risk-Free Rate of Return</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../06/06.00.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">6. Conic Optimization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The MO Book Group<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>